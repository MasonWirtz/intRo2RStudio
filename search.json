{
  "articles": [
    {
      "path": "about.html",
      "title": "Preliminaries",
      "description": "Starting information about the workshop\n",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nWorkshop details\nGetting started\nCreate an OSF account (voluntary)\nPrevious knowledge\nTopics\nLanguage\n\nWorkshop details\nThis workshop takes place on the 18. and 19. of MARCH, 2022.\n18. March: 13:00—17:00\n19. March: 09:00—17:00 (11:30—13:00 LUNCH)\nPlace: University of Salzburg, Unipark (Erabzt-Klotz-Straße 1)\nRoom: 3.206\nGetting started\nIn this workshop, we will learn the basics of (a) using the free programming language R; (b) how to work in RStudio; (c) how to write and format reports using R Markdown and (d) how to structure R projects in a manner that eases the workflow when working quantitatively, but also facilitates easy reproducibility of the analyses. The workshop is geared towards PhD students interested in working quantitatively and is freely open to any interested faculty as well as MA students. All parts of the workshop will include hands-on exercises. At the end of the workshop, you will also have free time to use your own data, ask me questions and get feedback.\nCreate an OSF account (voluntary)\nThe second part of this workshop is going to deal with open data and reproducibility. One of the most used open data repositories is the Open Science Framework (OSF). Accounts are, of course, free and easy to set up. Under this link you can find a guide on how to create an account. Feel free to browse the website—take a look at other peoples’ repositories: How do they structure their open data? What trends do you see? Do some structures seem to make more or less sense to you? Of course, you don’t have to do this in preperation for the workshop, but it can certainly never hurt!\nYou won’t explicitely need an OSF account for this workshop, so this step is really entirely up to you. I would, however, highly recommend it—especially because you can store data here. If you create a repository, it is not automatically open to the public. You can store 5GB of data (of whatever type) in a repository, and it is one of the most secure networks for the sciences. You can then create a share-only like or edit link for collaboration. As far as I am aware, there is no limit to the amount of repositories you can create, so you can use this to collaborate—it is absolutely great!\nAs soon as a repository is open to the public, you then have 50GB of storage on the respective project/repository (since the goal here is, after all, open data/open science). We will go through a few walk-throughs of the website and how you can also store more than 5GBs on a private repository, if you should ever need that.\nPrevious knowledge\nIn general, there is no previous knowledge required to partake in this workshop, but very basic experience with R or RStudio is definitely helpful, as we will be covering the basics relatively quickly.\nI highly reccomend, before coming to this workshop, that you read the first chapter of Bodo Winter’s Statistics for Linguists: An Introduction using R if you have not worked with R until this workshop. Even if you don’t work along with the exercises in the book, simply reading the first chapter will give you a feel of what R is as a programming language. And if you are also in need of an introduction to the regression framework, this book is one for you!\nAlternatively, I can highly recommend Michael Franke’s An Introduction to Data Analysis, chapters 2.1–2.3, for a beginning look at R.\nTopics\nParticipants should leave this workshop with surer footing in the following areas:\nBasic coding in RStudio (we will largely use the Tidyverse)\nTypes of variables (vectors, factors, data frames)\nImporting data\nSetting up an R Markdown document\nEnsuring reproducible and understandable code\nStructuring an R project (folders, files, project management etc.)\nUsing OSF (Open Science Framework) to store data\nLanguage\nThe workshop material will be in English, but questions/discussions can be in German.\nSince most of the literature I have read hitherto (and most of the existing literature) on the topics we will be covering in this workshop are in English, I personally feel more comfortable speaking and creating the necessary material in English, as I’m not entirely sure I could explain the concepts with the correct vocabulary in German. This is my own personal shortcoming, and I apologize if this is an inconvenience for anyone.\n\n\n\n",
      "last_modified": "2022-03-09T21:42:13+01:00"
    },
    {
      "path": "DataGeneration.html",
      "title": "Data generation script",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\nThis script shows the code for generating the necessary data frames used in the workshop.\n\n\nlibrary(tidyverse)\n\nVampires =\n  tibble(\n  idVampire = 1:100,\n  gender = rnorm(n = 100, mean = 0, sd = 1),\n  ageOfVampire = abs(round(rnorm(n = 100, mean = 80, sd = 30))),\n  deadOrAlive = rnorm(n = 100, mean = 0, sd = 1),\n  hasFangs = rnorm(n = 100, mean = 0, sd = 1),\n  bornIn = rnorm(n = 100, mean = 5, sd = 2),\n  vampType = rnorm(n = 100, mean = 3, sd = 1),\n  wellbeing = runif(n = 100, min = 0, max = 100),\n  maritalStatus = rnorm(n = 100, mean = 3, sd = 1),\n  employment = rnorm(n = 100, mean = 0, sd = 1),\n  income = rnorm(n = 100, mean = 140000, sd = 30000),\n  visitedCities = round(abs(exp(rnorm(n = 100, mean = 3, sd = 1)))),\n  numberOfChildren = round(abs(rnorm(n = 100, mean = 3, sd = 2))),\n  numberChangedToVamp = round(abs(exp(rnorm(n = 100, mean = 2, sd = .5))))\n) %>%\n  mutate(idVampire = as.factor(idVampire),\n         gender = ifelse(gender < 0, \"Male\", \"Female\"),\n         deadOrAlive = ifelse(deadOrAlive < 0, \"Dead\", \"Alive\"),\n         hasFangs = ifelse(hasFangs < 0, \"Yes\", \"No\"),\n         vampType = ifelse(vampType <= 2, \"sanguinarian\", \n                           ifelse(vampType > 2 & vampType < 3, \"psychic\", \"hybrid\")),\n         maritalStatus = ifelse(maritalStatus <= 2, \"Married\", \n                                ifelse(maritalStatus > 2 & maritalStatus < 3, \n                                       \"Single\", \"Divorced\")),\n         employment = ifelse(employment < 0, \"Employed\", \"Not Employed\"),\n         bornIn = ifelse(bornIn < 1, \"Asia\",\n                         ifelse(bornIn >= 1 & bornIn < 2, \"Africa\",\n                                ifelse(bornIn >= 2 & bornIn < 3, \"Europa\",\n                                       ifelse(bornIn >= 3 & bornIn < 4, \"North America\",\n                                              ifelse(bornIn >= 4 & bornIn < 5, \"South America\",\n                                                     ifelse(bornIn >= 5 & bornIn < 6, \"Australia\", \"Antarctica\")))))))\n\nwrite_csv(Vampires, file = \"./Data/Vampires.csv\") # write the file\n\n\n\nExport the mtcars and swiss data frames as a .csv files to upload to the workshop website.\n\n\nwrite_csv(mtcars, file = \"./Data/mtcars.csv\")\n\nwrite_csv(swiss, file = \"./Data/swiss.csv\")\n\n\n\n\n\n\n",
      "last_modified": "2022-03-09T21:42:35+01:00"
    },
    {
      "path": "ExercisesUnit2.html",
      "title": "2. Baby steps: Basics of coding in RStudio, part 1",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3\nExercise 4\nExercise 5\nExercise 6\nExercise 7\n\nExercise 1\nCreate an object (i.e. variable, container) called\ntestObject and store five numbers in it.\n\nClick for Answer\nCreating and storing different types of vectors is one of the most\nessential skills you will need for using R. These first few exercises\nmay seem really trivial, but I promise, you will use these trivial\nskills so often that you will quickly realize how not trivial they\nare.\nSOLUTION\nOkay, so we need an object called testObject. This part\nis easy enough. All I have to do is type testObject. The\ntricky part is storing something in the object. In this example, we just\nneed to store five numbers in this object. Let’s go ahead and make our\nlives easy by just using the numbers 1 through 5. We can store the\nnumbers 1 through 5 in an object in a few different ways. Let’s have a\nlook at those few different ways.\nThe way a beginner thinks would probably be to save the numbers in\nthe object like so:\n\n\ntestObject = c(1, 2, 3, 4, 5)\n\n\n\nThis most certainly isn’t wrong, and we achieved our goal. Good,\nright? Yes, it is! If you did something similar above, that’s great. It\nmeans you’ve gotten a grasp on the basics.\nBut, let’s say we want to be lazy. If I have even ten numbers, typing\nthe number and comma is a lot of work. I don’t like work. So let’s make\na our lives a little easier by using the fabulous : that R\nprovides us with to make a sequence of numbers, like so:\n\n\ntestObject = 1:5\n\n\n\nSince we are also not stringing numbers together, but using the\nsequence operator :, we do not need to concatenate function\nc()–you can use it if you want, but you don’t need it.\nEverything clear? Hervorragend, then let’s move on to the next\nexercise.\nExercise 2\nCreate a character vector of your name and save it\nas the object Name\nHINT: The individual elements of a character vector\nmust be under quotation marks\n\nClick for Answer\nSOLUTION\nI tend to use character vectors quite often (we will hear later in\nthis workshop why), so I find it important to take a little bit of time\nto get to know them.\nIf we want a character vector consisting of different individual\nelements, then you know what that means: IT’S CONCATINATE TIME! We need\nthe c() in order to string together different character\nelements, like so:\n\n\nName = c(\"Mason\", \"Allen\", \"Wirtz\")\n\n\n\nOf course, if you don’t need individual character elements (but I\nprefer them and oftentimes you also need the individual elements), you\ncan also solve this without concatenating things.\n\n\nName = \"Mason Allen Wirtz\"\n\n\n\nBut, using the c() and creating individual character\nelements gives us more freedom to play around with the vector. More on\nthis later.\nExercise 3\nCreate a vector named numbers and save the sequence\n1–100 in it.\n\nClick for Answer\nSOLUTION\nI hinted about this above: If we want to have a larger data frame, it\nwould take us sooooo long to do c(1, 2, 3, 4, 5, 6, …), I personally\nwould die of boredom. Luckily, we can use the : operator\nand let R work its magic and create us a sequence of numbers between 1\nand 100, namely like so:\n\n\nnumbers = 1:100\n\n\n\nExercise 4\nIn R, we have arithmetic operators (we will go into logical operators\nlater) with which we can do simple math. Below, you can find a list of\nthese, which are all very self-explanatory.\nOperator\nDescription\n+\nAddition\n-\nSubtraction\n*\nMultiplication\n/\nDivision\n^ OR **\nExponentiation\nAdd 1 and 1 together to get two\n\nClick for Answer\nSOLUTION\nI think this one is pretty self-explanatory, but just in case:\n\n\n1 + 1\n\n\n[1] 2\n\nExercise 5\nWe can also add vectors together, provided they are numeric. Add the\ntwo vectors below together–why does R throw an error?\n\n\na = 4:9\nb = 10:17\n\n\n\nWhat would we need to do in order to fix this error?\n\nClick for Answer\nSOLUTION\nOnly vectors of the same length can meaningfully be added/subtracted\netc. Since vector a contains six values, and vector\nb eight values, R added the fist six values together of the\ntwo vectors. Since vector b is longer than vector\na though, the last two numbers in vector b\nwere added to the first two numbers in vector a.\nBasically, vector b realized, “oh no, there are no more\nnumbers in vector a, what do I do?! Oh, I know, I’ll take\nthe first two numbers of vector a and add them to my own\nlast two values!”. R threw us an error to make us aware of this.\nExercise 6\nCreate two vectors (using whatever numerical values you’d like) under\nthe names a and b (the two variables above\nwill be overwritten) and divide the two vectors.\n\nClick for Answer\nSOLUTION\nNothing we haven’t already seen here. We’ll start with generating two\nvectors, like so:\n\n\na = 1:100\nb = 101:200\n\n\n\nAnd then let’s go ahead and just divide them by each other. The\nlovely thing about vectors and being able to save them as objects is\nthat it makes doing simple arithmetic operations like this so easy and\nreadable!\n\n\na/b\n\n\n  [1] 0.00990099 0.01960784 0.02912621 0.03846154 0.04761905\n  [6] 0.05660377 0.06542056 0.07407407 0.08256881 0.09090909\n [11] 0.09909910 0.10714286 0.11504425 0.12280702 0.13043478\n [16] 0.13793103 0.14529915 0.15254237 0.15966387 0.16666667\n [21] 0.17355372 0.18032787 0.18699187 0.19354839 0.20000000\n [26] 0.20634921 0.21259843 0.21875000 0.22480620 0.23076923\n [31] 0.23664122 0.24242424 0.24812030 0.25373134 0.25925926\n [36] 0.26470588 0.27007299 0.27536232 0.28057554 0.28571429\n [41] 0.29078014 0.29577465 0.30069930 0.30555556 0.31034483\n [46] 0.31506849 0.31972789 0.32432432 0.32885906 0.33333333\n [51] 0.33774834 0.34210526 0.34640523 0.35064935 0.35483871\n [56] 0.35897436 0.36305732 0.36708861 0.37106918 0.37500000\n [61] 0.37888199 0.38271605 0.38650307 0.39024390 0.39393939\n [66] 0.39759036 0.40119760 0.40476190 0.40828402 0.41176471\n [71] 0.41520468 0.41860465 0.42196532 0.42528736 0.42857143\n [76] 0.43181818 0.43502825 0.43820225 0.44134078 0.44444444\n [81] 0.44751381 0.45054945 0.45355191 0.45652174 0.45945946\n [86] 0.46236559 0.46524064 0.46808511 0.47089947 0.47368421\n [91] 0.47643979 0.47916667 0.48186528 0.48453608 0.48717949\n [96] 0.48979592 0.49238579 0.49494949 0.49748744 0.50000000\n\nWhat R did here was divide each number in the vector a\nby the number in the same position in vector b (i.e. 1/101,\n2/102, 3/103 etc.), so we should wind up with a vector of 100 values in\ntotal.\nExercise 7\nAlright, let’s say we ran an experiment and tested the reaction times\nof a language learner once a day for seven days. We have the reaction\ntimes (these are provided for you, see below), but we want to make a\nvector with the days of the week.\nCreate a character vector with the days of the week and save it as\ndaysOfTheWeek\n\nreactionTimes = rnorm(n = 7, mean = .25, sd = .1) # you don't need to do anything here\n\ndaysOfTheWeek =\n\n\nClick for Answer\nSOLUTION\nAll we have to do here is string together the days of the week and\nsave it under the object daysOfTheWeek, only this time we\nhave a character vector (similar to what we had with our name).\n\n\nreactionTimes = rnorm(n = 7, mean = .25, sd = .1) # you don't need to do anything here\n\ndaysOfTheWeek = c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\n\n\n\nThere is also a nice little base R function (we will learn more about\nfunctions later) called weekdays(), which takes a date as\nan argument. I put together a few variations of how to generate weekdays\nusing this function, in case anyone ever really needs to add this to a\ndata set. Just run the code lines and have a quick look at the\noutput.\nIt’s probably important to mention here: There is always an elegant\nsolution to any question, and probably an easier way to do it. While\ntyping the whole vector our like in my solution above is easy, these\nsolutions are also quite elegant and easily readable. Just food for\nthought.\n\n\nweekdays(ISOdate(1, 1, 1:7))\n\n\n[1] \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"   \n[6] \"Saturday\"  \"Sunday\"   \n\nweekdays(Sys.Date()+0:6) # days of the week starting on whatever day today is\n\n\n[1] \"Wednesday\" \"Thursday\"  \"Friday\"    \"Saturday\"  \"Sunday\"   \n[6] \"Monday\"    \"Tuesday\"  \n\nweekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6)\n\n\n[1] \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"   \n[6] \"Saturday\"  \"Sunday\"   \n\nWe could then combine these two vectors to create a data frame using\nthe function data.frame() from base R (we will learn more\nabout functions in the next section), like so:\n\n\ndata.frame(daysOfTheWeek, reactionTimes)\n\n\n  daysOfTheWeek reactionTimes\n1        Monday     0.2888160\n2       Tuesday     0.1972332\n3     Wednesday     0.2532501\n4      Thursday     0.3731675\n5        Friday     0.2436066\n6      Saturday     0.3075222\n7        Sunday     0.2995326\n\n\n\n\n",
      "last_modified": "2022-11-16T20:33:17+01:00"
    },
    {
      "path": "ExercisesUnit3.html",
      "title": "3. Baby steps: Basics of coding in RStudio, part 2",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExcercise 1\nExercise 2\nExercise 3\nExercise 3.1\nExercise 3.2\nExercise 3.3\n\nExercise 4\n\nExcercise 1\nAlright, so we’ve gotten to know a few functions. Let’s go ahead and\nreview some of the important ones, specifically the ones that we use\nreally often, like the summary statistics.\nCompute the mean, sd, min and max of the ageOfVampire\nvariable in the Vampires data frame.\n\nClick for Answer\nSOLUTION\n\n\nmean(Vampires$ageOfVampire)\n\n\n[1] 84.5\n\nsd(Vampires$ageOfVampire)\n\n\n[1] 32.79366\n\nmin(Vampires$ageOfVampire)\n\n\n[1] 14\n\nmax(Vampires$ageOfVampire)\n\n\n[1] 198\n\nRemember, when we want to reach into a data frame, we need to use the\n$ operator. This tells R to reach into a specific data\nframe and carry out the function on the variable that comes after the\n$ operator.\nExercise 2\nNice job, you’re doing fantastic! So, since you were able to complete\nthe last activity, let’s kick it up a notch and get to some fun\nstuff.\nYou’ve had a hard day, because, let’s be honest, that’s academia. You\nneed some encouragement, but no one is home to tell you how amazing you\nare. Let’s fix this!\nLoad in the package called praise and then call the\npraise() function. Run this as many times as you need until\nyou feel like the awesomest person on Earth, because you are!!\n\nClick for Answer\nSOLUTION\n\n\n# install.packages(\"praise\")\nlibrary(praise)\npraise()\n\n\n[1] \"You are stupendous!\"\n\nRemember, if we haven’t installed a package yet, we ALWAYS need to\nrun the install.packages() function, with the package name\nin parentheses. After that, we need to LOAD the package, cause otherwise\nwe have ‘downloaded’ it, but we haven’t actually ‘opened’ it yet.\nExercise 3\nAlright, so now that we know how to load in packages and call some\nuseful functions, what happens if we forget functions, or if we have\nsomething we want to do, but don’t remember or know a helpful function\nfor this? Well, GOOGLE is our friend!\nIn our Vampires data frame, we want to know how many\nmale and female vampires there are. There are a few important steps we\nneed to take to do this.\nExercise 3.1\nFIRST, we NEED to make sure that all of our variables that should be\ntreated as factor vectors are, indeed, factors. If you have read in the\nVampires data set, chances are the gender variable was\nsaved as a character vector, which we don’t want.\nGo on Google and try to find out which function we can use to change\na CHARACTER vector in a data frame to a FACTOR vector (googling\nsomething like “change character to factor in r” should do the trick).\nYour GOAL is to change the gender variable in the\nVampires data frame from a CHARACTER vector to a FACTOR\nvector (you can see if it worked using the\nclass(Vampires$gender) function.)\n\nClick for Answer\nSOLUTION\nSo, there are actually a lot of ways to do this, depending on whether\nyou are using tidyverse (we will learn about this in the next section)\nor base R. I’ll show you a Base R example.\nSo, in base R, we work with our $ operator. Since we\nwant to change a vector in a data frame, we will first have to tell R to\nchange a vector in the data frame, which we do by defining a new\nvariable Vampires$gender. Since we already have\ngender in the Vampires data frame, by defining\nour variable in this way, it will overwrite the character vector as a\nfactor vector.\n\n\nVampires$gender = as.factor(Vampires$gender)\n\n\n\nExercise 3.2\nAwesome, you’re doing so well! So, since we have now changed our\ngender variable to a factor, we can now count the\nfactor levels, i.e. how many different levels does the factor\nhave (in our case, I only entered female/male for the sake of\nsimplicity). Use the table() function to count the factor\nlevels of the factor gender (what do we need to feed into\nthe table() function to make it count the factor\nlevels?)\n\nClick for Answer\nSOLUTION\nYou guessed it! All we need to do is enter the classic\nVampires$gender into the table function to have it count\nthe number of factor levels each.\n\n\ntable(Vampires$gender)\n\n\n\nFemale   Male \n    56     44 \n\nExercise 3.3\nLet’s use what we just learned to answer the following questions:\nHow many vampires in the data frame are dead, and how many\nalive?\nHow many vampires were born on each continent?\nHow many vampires are married and how many divorced?\n\nClick for Answer\nSOLUTION\nHow many vampires in the data frame are dead, and how many\nalive?\nWell, we first have to factor our variable, then use the\ntable() function.\n\n\nVampires$deadOrAlive = as.factor(Vampires$deadOrAlive)\ntable(Vampires$deadOrAlive)\n\n\n\nAlive  Dead \n   59    41 \n\nHow many vampires were born on each continent?\n\n\nVampires$bornIn = as.factor(Vampires$bornIn)\ntable(Vampires$bornIn)\n\n\n\n       Africa    Antarctica          Asia     Australia        Europa \n            2            30             2            15             5 \nNorth America South America \n           19            27 \n\nHow many vampires are married and how many divorced?\n\n\nVampires$maritalStatus = as.factor(Vampires$maritalStatus)\ntable(Vampires$maritalStatus)\n\n\n\nDivorced  Married   Single \n      47       20       33 \n\nOh my God, why are so many divorced?!\nExercise 4\nAlright, we’re going to do some really fun statistics, cause why\nnot?\nTry to do the following (feel free to group up for these!)\nWhich variables in the Vampires data frame are\nNUMERIC?\nChoose two NUMERIC variables and run a correlation using the\ncor.test() function. This is a fantastic chance to use the\nhelp environment to find out what you should enter into the\ncor.test() function! smiley emoji\nInstall and load the package report. Go back and\nsave your correlation test as the variable cor. Then run\nreport(cor) and thank me later.\nINTERMEDIATE: Change the type of the correlation to a Spearman’s\ncorrelation.\n\nClick for Answer\nSOLUTION\nWhich variables in the Vampires data frame are\nNUMERIC?\nSo, this one is pretty easy, but we need to know the right function\nto do this! We can easily use the str() function, cause\nthis gives us the classes of all variables in a data frame.\n\n\nstr(Vampires)\n\n\nspec_tbl_df [100 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ idVampire          : num [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n $ gender             : Factor w/ 2 levels \"Female\",\"Male\": 1 2 2 2 1 2 1 1 2 2 ...\n $ ageOfVampire       : num [1:100] 89 192 67 23 40 105 58 67 88 122 ...\n $ deadOrAlive        : Factor w/ 2 levels \"Alive\",\"Dead\": 2 2 2 2 1 1 1 1 1 2 ...\n $ hasFangs           : chr [1:100] \"No\" \"Yes\" \"Yes\" \"No\" ...\n $ bornIn             : Factor w/ 7 levels \"Africa\",\"Antarctica\",..: 6 6 7 5 4 2 4 6 2 2 ...\n $ vampType           : chr [1:100] \"hybrid\" \"hybrid\" \"sanguinarian\" \"psychic\" ...\n $ wellbeing          : num [1:100] 61.6 71.4 64.2 24.7 47.2 ...\n $ maritalStatus      : Factor w/ 3 levels \"Divorced\",\"Married\",..: 3 1 1 2 1 2 3 1 3 3 ...\n $ employment         : chr [1:100] \"Employed\" \"Employed\" \"Not Employed\" \"Employed\" ...\n $ income             : num [1:100] 131670 153860 154087 113842 144047 ...\n $ visitedCities      : num [1:100] 10 4 3 97 33 41 43 119 16 11 ...\n $ numberOfChildren   : num [1:100] 3 1 1 2 3 1 5 1 4 1 ...\n $ numberChangedToVamp: num [1:100] 23 7 9 11 3 5 13 21 4 8 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   idVampire = col_double(),\n  ..   gender = col_character(),\n  ..   ageOfVampire = col_double(),\n  ..   deadOrAlive = col_character(),\n  ..   hasFangs = col_character(),\n  ..   bornIn = col_character(),\n  ..   vampType = col_character(),\n  ..   wellbeing = col_double(),\n  ..   maritalStatus = col_character(),\n  ..   employment = col_character(),\n  ..   income = col_double(),\n  ..   visitedCities = col_double(),\n  ..   numberOfChildren = col_double(),\n  ..   numberChangedToVamp = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\nChoose two NUMERIC variables and run a correlation using the\ncor.test() function. This is a fantastic chance to use the\nhelp environment to find out what you should enter into the\ncor.test() function! smiley emoji\nSo, if you know a little about statistics, you know that a\ncorrelation is just the strength of the association between two\nvariables. This logically means that we need to enter two variables into\nthe correlation analysis. Let’s say we want to know whether income\ncorrelates with wellbeing in vampires. REMEMBER, we need to define in\nwhich data frames our variables are coming from using the $\noperator!!\n\n\ncor.test(Vampires$wellbeing, Vampires$income)\n\n\n\n    Pearson's product-moment correlation\n\ndata:  Vampires$wellbeing and Vampires$income\nt = 2.5368, df = 98, p-value = 0.01276\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.05447568 0.42398305\nsample estimates:\n      cor \n0.2482377 \n\nNice, looks like there is something going on there! (Remember, since\nthe data generated here are generated newly every time I remake the\nwebsite, the results you get could be entirely different, so don’t let\nthis scare you!! If you got a result, then you did it just fine, go\nyou!)\nInstall and load the package report. Go back and save\nyour correlation test as the variable cor. Then run\nreport(cor) and thank me later.\n\n\n# install.packages(\"report\")\nlibrary(report)\n\ncor = cor.test(Vampires$income, Vampires$wellbeing)\nreport(cor)\n\n\nEffect sizes were labelled following Funder's (2019) recommendations.\n\nThe Pearson's product-moment correlation between Vampires$income and\nVampires$wellbeing is positive, statistically significant, and medium\n(r = 0.25, 95% CI [0.05, 0.42], t(98) = 2.54, p = 0.013)\n\nINTERMEDIATE: Change the type of the correlation to a Spearman’s\ncorrelation.\n\n\ncor.test(Vampires$income, Vampires$wellbeing, method = \"spearman\")\n\n\n\n    Spearman's rank correlation rho\n\ndata:  Vampires$income and Vampires$wellbeing\nS = 119390, p-value = 0.004373\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.2835884 \n\n\n\n\n",
      "last_modified": "2022-11-16T20:02:31+01:00"
    },
    {
      "path": "ExercisesUnit4.html",
      "title": "4. The tidier the better: Basics of coding with the Tidyverse",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3\nExercise 4\nExercise 5 (intermediate)\nExercise 5.1\nExercise 5.2\nExercise 5.3\n\nExercise 6 (for experts)\n\nExercise 1\nLoad in the data Vampires (preferably as a tibble using\nthe read_csv() function).\nWe are only interested in the columns idVampire,\ngender, ageOfVampire and\nnumberOfChildren. Create a new data frame called\nVamps including only these columns.\n\nClick for Answer\nSOLUTION\nSince our goal here is to simply subset the data frame and select on\ncertain columns, we can use the function select() from the\ndplyr package included in the tidyverse. This\nwill allow us to pick and choose which columns we want to subset. We can\nthen assign these subsetted variables to a new object, which the\ndirections ask us to call Vamps. Let’s go ahead and do\nthis:\n\n\nVamps =                                       # define object\n  Vampires %>%                                # data\n  select(idVampire, gender,                   # select variables (i.e. subset data)\n         ageOfVampire, numberOfChildren)\n\n\n\nSince the first three columns we want to subset are in a row\n(i.e. the first three columns), we can also easily specify 1:3\n(i.e. columns 1 through 3), plus the variable\nnumberOfChildren, like so:\n\n\nVamps =                                 # define object\n  Vampires %>%                          # data\n  select(1:3, numberOfChildren)         # select variables (i.e. subset data)\n\n\n\nExercise 2\nCalculate the mean amount of cities the vampires have visited\n(variable: visitedCities), as well as the standard\ndeviation thereof, using the summarize() function.\n\nClick for Answer\nSOLUTION\nAs always, our first step is to reach into the data frame we are\ninterested in, namely Vampires, and then simply use the\nsummarize function, like so:\n\n\nVampires %>%                                       # dataa\n  summarize(mean = mean(visitedCities),            # calculate mean\n            sd = sd(visitedCities))                # calculate SD\n\n\n# A tibble: 1 × 2\n   mean    sd\n  <dbl> <dbl>\n1  32.5  39.7\n\nExercise 3\nCalculate the mean age of male and female vampires.\nHINT You will need the pipe ( %>% ) to\ngroup/stack functions, the group_by function and the\nsummarize function (in that order).\n\nClick for Answer\nSOLUTION\nAlright, so our first step, as always, is to specify which data frame\nwe are interested in. Then we want to group our data frame into two\ngroups, namely male and female, which can be done by using the\ngroup_by() function on the variable gender.\nAfter that, we need the summarize() function to calculate\nthe mean age (variable: ageOfVampire), like so:\n\n\nVampires %>% \n  \n  # Group the data frame by the gender variable, \n  # which is binary, i.e. only male or female.\n  group_by(gender) %>% \n  \n  # Summarize the grouped data \n  summarize(mean = mean(ageOfVampire))\n\n\n# A tibble: 2 × 2\n  gender  mean\n  <chr>  <dbl>\n1 Female  82.1\n2 Male    87.6\n\nExercise 4\nAlright, now we can get to the fun stuff: Manipulating data.\nTo start off, let’s clean up our environment a bit. We won’t really\nbe needing the Vamps data frame we made earlier, so remove it from your\nenvironment using the rm(Vamps) function.\nLet’s say we are interested in whether alive\nvampires have changed more people into vampires depending on\nwhether they have fangs or not. The variables here that will interest us\nare deadOrAlive, hasFangs and\nnumberChangedToVamp. There is no need to subset the\nrespective variables, but if you want to for the sake of practice, go\nahead.\nWhat is the mean number of people the alive vampires\nWITH and WITHOUT fangs have turned\ninto vampires?\nHINT You will need the pipe ( %>% ) to\ngroup/stack functions, the filter function, the\ngroup_by function and the summarize function\n(in that order).\n\nClick for Answer\nSOLUTION\nThis is pretty tricky, there are three steps we need to go through to\nget to the answer. Let’s go through this together.\nTo start with, we know that we are only interested in\nALIVE vampires, so this means that we need to subset\nthe data frame to home in on only the vampires that are alive. Our\nvariable deadOrAlive tells us whether the vampires are dead\nor alive, so this is the variable we first need to subset. We do this by\nusing the filter() function (remember, filter is for ROWS\nand select is for COLUMNS). And we specify we only want ALIVE vampires\nby using the == operator (REMEMBER, the operator = is\nfor assigning values to an object, == means “is equal to”).\nNow, since we are interested in whether vampires with and without\nfangs have changed more people to vampires, we need to group our data\nframe into two groups: vampires WITH fangs and vampires WITHOUT fangs.\nWe can do this by using the group_by() function.\nLastly, we then need the summarize function and\nspecify it to give us the mean of the people the vampires WITH and\nWITHOUT fangs have changed into vampires.\nWe have an interesting outcome, vampires without fangs have changed\nmore people into vampires on average than vampires with\nfangs…interesting. Maybe vampires without fangs have a\nMinderwertigkeitskomplex…?\n\n\nVampires %>% \n  \n  # Filter the data frame so that it \n  # ONLY includes vampires that are ALIVE\n  filter(deadOrAlive == \"Alive\") %>% \n\n  # Group the data frame by the hasFangs variable, \n  # which is binary, i.e. only yes or no. \n  \n  group_by(hasFangs) %>% \n  \n  # Summarize the grouped data \n  summarize(mean = mean(numberChangedToVamp))\n\n\n# A tibble: 2 × 2\n  hasFangs  mean\n  <chr>    <dbl>\n1 No        7.73\n2 Yes       8.73\n\nExercise 5 (intermediate)\nAlright, we are going to go through some REALLY useful functions that\nI tend to use relatively often. They are super practical when you need\nto sort your data.\nWe are going to focus on the following:\nstarts_with()\nends_with()\nwhere()\nacross()\ncontains()\ngrepl()\nSome of these are fairly self-explanatory (e.g., the first two), and\na lot of them are used really often in combination with the select\nfunction.\nRun the following code chunk: What happens? When do you think these\nfunctions might be useful?\n\n\nVampires %>% \n  select(starts_with(\"g\"))\n\n\n# A tibble: 100 × 1\n   gender\n   <chr> \n 1 Female\n 2 Male  \n 3 Male  \n 4 Male  \n 5 Female\n 6 Male  \n 7 Female\n 8 Female\n 9 Male  \n10 Male  \n# … with 90 more rows\n\nVampires %>% \n  select(ends_with(\"Vampire\"))\n\n\n# A tibble: 100 × 2\n   idVampire ageOfVampire\n       <dbl>        <dbl>\n 1         1           89\n 2         2          192\n 3         3           67\n 4         4           23\n 5         5           40\n 6         6          105\n 7         7           58\n 8         8           67\n 9         9           88\n10        10          122\n# … with 90 more rows\n\nI tend to use this function quite a bit when I work with z-scored\nvariables, because I name all of them variable_z, so I can\neasily run the function select(ends_with(\"_z\")), which is\nof course really handy if I just want a data frame with my z-scored\npredictor variables.\nThe where() function is really handy when you want to\nsort based on the class of a vector in a data frame. For exaample, is we\nwant to select all columns that are numeric in class, we can run the\nfollowing function:\n\n\nVampires %>% \n  select(where(is.numeric))\n\n\n# A tibble: 100 × 7\n   idVampire ageOfVampire wellbeing  income visitedC…¹ numbe…² numbe…³\n       <dbl>        <dbl>     <dbl>   <dbl>      <dbl>   <dbl>   <dbl>\n 1         1           89      61.6 131670.         10       3      23\n 2         2          192      71.4 153860.          4       1       7\n 3         3           67      64.2 154087.          3       1       9\n 4         4           23      24.7 113842.         97       2      11\n 5         5           40      47.2 144047.         33       3       3\n 6         6          105      23.9 138654.         41       1       5\n 7         7           58      38.8 183873.         43       5      13\n 8         8           67      73.1 136873.        119       1      21\n 9         9           88      51.4 109140.         16       4       4\n10        10          122      70.6 149289.         11       1       8\n# … with 90 more rows, and abbreviated variable names ¹​visitedCities,\n#   ²​numberOfChildren, ³​numberChangedToVamp\n\nThe across() function basically tells R to do something\nacross a certain amount of columns So, if I want R to summarize\nall of my numeric variables reaally quickly, I could run something like\nthis:\n\n\nVampires %>% \n  summarise(across(where(is.numeric), mean))\n\n\n# A tibble: 1 × 7\n  idVampire ageOfVampire wellbeing  income visitedCi…¹ numbe…² numbe…³\n      <dbl>        <dbl>     <dbl>   <dbl>       <dbl>   <dbl>   <dbl>\n1      50.5         84.5      51.0 142011.        32.5    3.07     8.2\n# … with abbreviated variable names ¹​visitedCities,\n#   ²​numberOfChildren, ³​numberChangedToVamp\n\nAnd, if I want multiple statistics, I can do this easily, too:\n\n\nVampires %>% \n  summarise(across(where(is.numeric), c(mean = mean, sd = sd, min = min, max = max)))\n\n\n# A tibble: 1 × 28\n  idVampire_…¹ idVam…² idVam…³ idVam…⁴ ageOf…⁵ ageOf…⁶ ageOf…⁷ ageOf…⁸\n         <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1         50.5    29.0       1     100    84.5    32.8      14     198\n# … with 20 more variables: wellbeing_mean <dbl>, wellbeing_sd <dbl>,\n#   wellbeing_min <dbl>, wellbeing_max <dbl>, income_mean <dbl>,\n#   income_sd <dbl>, income_min <dbl>, income_max <dbl>,\n#   visitedCities_mean <dbl>, visitedCities_sd <dbl>,\n#   visitedCities_min <dbl>, visitedCities_max <dbl>,\n#   numberOfChildren_mean <dbl>, numberOfChildren_sd <dbl>,\n#   numberOfChildren_min <dbl>, numberOfChildren_max <dbl>, …\n\nExercise 5.1\nThe contains() function does the same as (a) and (b),\nreally, but it selects any COLUMNS that contain a certain string. Use\nthis function to to select any COLUMNS that contain the word\nVampire\n\nClick for Answer\nSOLUTION\nThis works the same was as the starts_with() etc.\nfunctions, so we just define “Vampire” in our contains()\nfunction.\n\n\nVampires %>% \n  select(contains(\"Vampire\"))\n\n\n# A tibble: 100 × 2\n   idVampire ageOfVampire\n       <dbl>        <dbl>\n 1         1           89\n 2         2          192\n 3         3           67\n 4         4           23\n 5         5           40\n 6         6          105\n 7         7           58\n 8         8           67\n 9         9           88\n10        10          122\n# … with 90 more rows\n\nExercise 5.2\nThe grepl() function is similar, but it filters anything\nwith a certain string. HOWEVER, we also have to specify in WHICH COLUMN\nit is.\nWhich function do we use to subset ROWS (instead of columns)?\nHow would we subset our data set depending on which vampires were\nborn in any of the Americas?\nHINT: You will have to use\ngrepl(\"America\", bornIn), but this has to be wrapped in\nanother function (but which one? Hmmm…)\n\nClick for Answer\nSOLUTION\nThis one is pretty tricky! We first need to use the\nfilter() function since we are filtering ROWS. Then, we use\nthe grepl() function to define a certain string of what we\nwant the code to search for, and then finally define in which COLUMN the\ncode should search.\n\n\nVampires %>% \n  filter(grepl(\"America\", bornIn))\n\n\n# A tibble: 46 × 14\n   idVampire gender ageOfVamp…¹ deadO…² hasFa…³ bornIn vampT…⁴ wellb…⁵\n       <dbl> <chr>        <dbl> <chr>   <chr>   <chr>  <chr>     <dbl>\n 1         1 Female          89 Dead    No      North… hybrid     61.6\n 2         2 Male           192 Dead    Yes     North… hybrid     71.4\n 3         3 Male            67 Dead    Yes     South… sangui…    64.2\n 4         8 Female          67 Alive   Yes     North… hybrid     73.1\n 5        11 Male            61 Alive   Yes     South… psychic    51.5\n 6        13 Female          87 Alive   No      North… hybrid     19.5\n 7        17 Female          89 Alive   Yes     South… psychic    97.0\n 8        20 Male            99 Dead    Yes     South… sangui…    53.8\n 9        23 Male            99 Dead    No      North… hybrid     23.6\n10        24 Male            61 Alive   No      North… psychic    68.0\n# … with 36 more rows, 6 more variables: maritalStatus <chr>,\n#   employment <chr>, income <dbl>, visitedCities <dbl>,\n#   numberOfChildren <dbl>, numberChangedToVamp <dbl>, and\n#   abbreviated variable names ¹​ageOfVampire, ²​deadOrAlive,\n#   ³​hasFangs, ⁴​vampType, ⁵​wellbeing\n\nExercise 5.3\nLet’s say that we know we do not want any character vectors in our\ndata frame, but we rather want these to be factor vectors. Using the\nmutate(), across() and where()\nfunctions, change ALL character vectors to factor vectors. This one is a\nbit tricky, but, once you know this trick, you will use it SO\nOFTEN!!!\n\nClick for Answer\nSOLUTION\nThis one is pretty tricky! We first need the mutate()\nfunction because we want to change the variables. Then, we need\nacross() because we are mutating across several variables,\nand we need to tell the function across which variables we are\nmutating, so we use the where() function. Since we want to\nmutate all CHARACTER vectors, we need to search for where these vectors\nare, which we can do with the is.character function. Then,\nwe tell the function what to do once it has located the character\nvectors, which is then to change them to factors, which we do by using\nthe as.factor() function.\n\n\nVampires %>% \n  mutate(across(where(is.character), as.factor))\n\n\n# A tibble: 100 × 14\n   idVampire gender ageOfVamp…¹ deadO…² hasFa…³ bornIn vampT…⁴ wellb…⁵\n       <dbl> <fct>        <dbl> <fct>   <fct>   <fct>  <fct>     <dbl>\n 1         1 Female          89 Dead    No      North… hybrid     61.6\n 2         2 Male           192 Dead    Yes     North… hybrid     71.4\n 3         3 Male            67 Dead    Yes     South… sangui…    64.2\n 4         4 Male            23 Dead    No      Europa psychic    24.7\n 5         5 Female          40 Alive   Yes     Austr… hybrid     47.2\n 6         6 Male           105 Alive   No      Antar… psychic    23.9\n 7         7 Female          58 Alive   Yes     Austr… hybrid     38.8\n 8         8 Female          67 Alive   Yes     North… hybrid     73.1\n 9         9 Male            88 Alive   No      Antar… hybrid     51.4\n10        10 Male           122 Dead    Yes     Antar… psychic    70.6\n# … with 90 more rows, 6 more variables: maritalStatus <fct>,\n#   employment <fct>, income <dbl>, visitedCities <dbl>,\n#   numberOfChildren <dbl>, numberChangedToVamp <dbl>, and\n#   abbreviated variable names ¹​ageOfVampire, ²​deadOrAlive,\n#   ³​hasFangs, ⁴​vampType, ⁵​wellbeing\n\nExercise 6 (for experts)\nAlright, you’ve done well until now? Great! Let’s take on a harder\ntask. Before you start, look up the arguments for the function\nungroup().\nLet’s say we had participants complete several versions of a C Test\n(a language assessment test in which participants have to complete\nwords—this has been shown to strongly correlate with participants’\ngeneral language proficiency, cf. Raatz & Klein–Braley [2002]).\nSince no two tests are typically exactly the same, even after pilot\ntesting (that is, without conducting large-scale psycho-metric validity\nscreenings), we tend to correct for the possible differences in the\ntasks statistically. We can correct for differences (to help ensure\nbetter comparability) between the versions of the C Test by subtracting\nor adding the deviation of each version’s mean count from the overall\nmean count for each individual score.\nLet me generate some data for you that replicates this situation:\n\n\n# RUN THE FOLLOWING CODE CHUNK\n\nCTest_df =                                                          # define object\n  tibble(Version = gl(n = 3, k = 20),                               # generate data\n         CTest = c(round(abs(rnorm(n = 20, mean = 17, sd = 4))),    # generate CTest 1\n                 round(abs(rnorm(n = 20, mean = 19, sd = 4))),      # generate CTest 2\n                 round(abs(rnorm(n = 20, mean = 20, sd = 4))))      # generate CTest 3\n) %>% \n  mutate(CTest = ifelse(CTest > 30, 30, CTest),                     # delete wild devs\n         CTest = ifelse(CTest < 0, 0, CTest)) \n\n# Let's have a look\nCTest_df\n\n\n# A tibble: 60 × 2\n   Version CTest\n   <fct>   <dbl>\n 1 1          20\n 2 1          20\n 3 1          13\n 4 1          17\n 5 1          22\n 6 1          19\n 7 1          19\n 8 1          15\n 9 1          14\n10 1          20\n# … with 50 more rows\n\nCTest_df %>% \n  group_by(Version) %>% \n  summarize_at(.vars = \"CTest\", \n               .funs = c(\"max\", \"min\", \"mean\", \"sd\"))\n\n\n# A tibble: 3 × 5\n  Version   max   min  mean    sd\n  <fct>   <dbl> <dbl> <dbl> <dbl>\n1 1          22     9  16.8  3.50\n2 2          26    10  17.6  4.15\n3 3          26    12  19.2  3.70\n\nSo, now we have a data frame with the version of the C Test\n(Version) and each participant’s score on the C Tests\n(CTest).\nAdjust the variable CTest by subtracting or adding the\ndifference of each C Test version’s mean score from the overall mean\nscore of the C Tests from or to each individual score.\nHINT You will need to (or can, there are other ways\nto solve this) use the following functions in the given order:\ngroup_by(), mutate(), ungroup()\nand mutate()\n\nClick for Answer\nSOLUTION\nSee the commented code below for the solution\n\n\nCTest_df %>% \n  \n  # First we need to group by version, \n  # since we need the mean of each \n  # VERSION of the CTest\n  group_by(Version) %>% \n  \n  # Now we create a NEW variable called \n  # CTestMean, which gives us the mean of \n  # each version\n  mutate(CTestMean = mean(CTest)) %>% \n  \n  # We haven't seen this function yet, \n  # but what it does is the exact opposite \n  # of the group_by() function, \n  # but instead of grouping the different \n  # levels of a factor, it ungroups them \n  # to give us back the actual data frame, \n  # just now with the new variable \n  # (i.e. CTestMean) we just created\n  ungroup() %>% \n  \n  # Now we need to create a few different variables: \n  # We need the OVERALL mean, i.e. the mean of ALL the \n  # C Test scores; We need the difference between the \n  # OVERALL mean score and the mean scores of each \n  # version of the C test. We then change the original \n  # CTest variable by adding the difference (positive or \n  # negative) to each individual CTest score\n  mutate(CTestMean_overall = mean(CTestMean), \n         CTestMean_difference = CTestMean_overall - CTestMean, \n         CTest = CTest + CTestMean_difference) %>% \n  \n  # Now we just get rid of the extra noise variables \n  # that we needed to calculate the adjusted C Test scores\n  select(-c(CTestMean, CTestMean_overall, CTestMean_difference))\n\n\n# A tibble: 60 × 2\n   Version CTest\n   <fct>   <dbl>\n 1 1        21.1\n 2 1        21.1\n 3 1        14.1\n 4 1        18.1\n 5 1        23.1\n 6 1        20.1\n 7 1        20.1\n 8 1        16.1\n 9 1        15.1\n10 1        21.1\n# … with 50 more rows\n\n\n\n\n",
      "last_modified": "2022-11-16T20:18:14+01:00"
    },
    {
      "path": "ExercisesUnit5.html",
      "title": "5. Setting up a project",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 2.1\nExercise 2.2\nExercise 2.3\nExercise 2.4 (Experts)\n\n\nExercise 1\nDownload Exercise script 5 from the workshop website. Save this script in the script folder we created in our new project structure.\nOn the workshop website, download the data frame mtcars and save this in the data folder we created in our new project structure.\nUsing the read_csv() function, load the data frame mtcars into your global environment and save this data frame under the variable name cars. Remember to use a RELATIVE PATH when loading in this data.\nHINT: Don’t forget to put the call in parentheses, and don’t forget the .\n\nClick for Answer\nSOLUTION\nIf we use the read_csv function, we are loading in our data as a tibble, which is really neat (thanks to the tidyverse package(s)). When we read in data from other folders, i.e. from places that are not in the same folder that our script is saved, we need to define the RELATIVE path, which in this case is \"./Data/mtcars.csv\". Since this data is saved in the Data folder, but our script is in the Script folder, we need to jump OUT of the Scripts folder (which is what the . does), and then jump INTO the Data folder (which is what the /Data/) does. Once we have defined this as our RELATIVE path, we can then enter the name of the data frame we want to load (which is mtcars.csv).\n\n\ncars = read_csv(\"./Data/mtcars.csv\")\n\n\n\nExercise 2\nWhen dealing with data, we oftentimes have functions that we write ourselves, because we use them over and over again. For example, if you used a questionnaire and formed items in the negative, you need to reverse this scale. An easy way to do this is to write a function that you can then use on all the items formulated in the reverse.\nExercise 2.1\nCreate a new folder in our folder structure called Functions (you can do this on your regular user system, i.e. how you would normally create a new folder). Make sure this folder is in the R you ready folder structure.\nDownload the script from the workshop website called reverseItems_Functions.R from the Exercise scripts drop-down pane. Save this script (saved under THE SAME NAME) in the functions folder.\nExercise 2.2\nOnce we have the functions saved in the Functions folder, we can use the lovely source() function to call up these functions and use them in a new script. I am a fan of the source() function (and maybe even overuse it…). It takes as its argument a RELATIVE path to an .R file.\nSource the reverseItems_Functions.R file that you saved in the Functions folder, using the RELATIVE path to this .R document. DON’T FORGET THE PARENTHESES!!\n\nClick for Answer\nUsing the relative path, we can source in the functions (and the data frame I included in this script). The source function runs and loads the script in its entirety, so if you created variables, data frames etc. in this script, those will be loaded along with the functions you wrote.\n\n\nsource(\"./Functions/reverseItems_Functions.R\")\n\n\n\nExercise 2.3\nLook at the variable item_6.3 using the call df_items$item_6.3. Then use the linkScaleRev6 function on the variable item_6.3. What did this function do?\n\nClick for Answer\nYou guessed it, this home-made function reversed the scale, turning 1s into 6s, 2s into 5s, and so forth. Isn’t that practical?!\nExercise 2.4 (Experts)\nTake a look at the reverseItems_Functions.R document and the functions I wrote. Write a function that reverses 7-scale items using the ifelse statement. Call this function linkScaleRev7 that takes the argument of an item\n\nClick for Answer\nIf you understood the functions I wrote, this activity shouldn’t be all that challenging :) All you need to do is add an extra ifelse() function to the mix, so that the entire scale is reversed.\n\n\n# reverse a 6-scale item ----\nlinkScaleRev7 =\n  function(item){\n    ifelse(item == 1, 7,\n           ifelse(item == 2, 6,\n                  ifelse(item == 3, 5,\n                         ifelse(item == 4, 4,\n                                ifelse(item == 5, 3,\n                                       ifelse(item == 6, 2, \n                                              ifelse(item == 7, 1, NA)))))))\n  }\n\n\n\n\n\n\n",
      "last_modified": "2022-03-09T21:42:53+01:00"
    },
    {
      "path": "ExercisesUnit6.html",
      "title": "6. Code chunks in R Markdown",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3 (intermediate level)\nExercise 3.1\nExercise 3.2\nExercise 3.3\nExercise 3.4\nExercise 3.5\n\n\nExercise 1\nCreate a new R Markdown document and name it “Exercise 6”. Delete the example content in the markdown document (from line 12 and down). Insert a new R chunk by clicking on the Insert button in the editor toolbar (this is the button with a white C in a green square) and choosing R.\nImport the Vampires.csv data set in this chunk using the read_csv() function and save this under the object Vampires. Don’t forget that this data frame should now be in our Data folder!!! Write the relative path in the read_csv() function accordingly!\n\nClick for Answer\nSOLUTION\nBy inserting a code chunk, we are effectively structuring our code in a readable manner and in a way that makes following what our process of analysis is easier. When you look back at your code after a time away from it, it is also much easier to understand what you yourself were thinking when coding. To read in the data frame we are interested in, we do this in our code chunks exactly the same way as we did when working with regular .R documents.\n\n\nVampires = read_csv(\"./Data/Vampires.csv\")         # read in data with a relative path\n\n\n\nExercise 2\nCreate a new code chunk using the Insert button in RStudio. In your new code chunk, complete the following exercise:\nUsing the help bar (or console), look up the arguments of the ifelse() function. What arguments does it take?\nUse the ifelse() function to create a new categorical variable called VampOld: All vampires older than 100 should be categorized as Old, all vampires younger than 100 should be categorized as Young.\nHINT You will need the mutate() function and the ifelse() function.\n\nClick for Answer\nSOLUTION\nSince we are interested in creating a new variable, this should tell us immediately that we need the mutate() function. In the mutate() function, we need to define our new variable VampOld.\nOnce we have defined the new variable, we need to define what should be included in the new variable. Since we want to categorize the age variable (which we really wouldn’t ever want to do in real life, but for practice, it’s an easy example), we can use the ifelse() statement, which first takes an argument to evaluate. The argument to evaluate we need to supply the function with is “if the vampire is older than 100…”, which we can do using the variable ageOfVampire and the > operator. Once we have supplied the ‘if’ argument, we need the ‘then do’ argument, i.e. what needs to happen when this argument is true? In this case, all vampires older than 100 should be categorized as ‘old’, so we supply the function with ‘old’. The final argument in the function takes the ‘else’ part, i.e. what happens when the first argument is false? Since we just want to categorize the variable into old and young, if the vampire is not old, then they must be young, so we supply the final argument with the character value ‘young’.\n\n\nVampires =                                  # define object              \n  Vampires %>%                              # data\n  mutate(VampOld =                          # define NEW VARIABLE\n           ifelse(ageOfVampire > 100,       # TEST (the \"if\" argument)\n                  \"Old\",                    # if the test is TRUE, change to OLD\n                  \"Young\"))                 # if the test is FALSE, change to YOUNG\n\n\n\nExercise 3 (intermediate level)\nYou can name R chunks in R Markdown, which is practical when structuring your analysis process. This can be done by writing a name beside the ` r at the top of the chunk, e.g. as follows\n\n\n# This is an example code chunk NAMED \"example\"\n\n\n\nWe are going to run a simple linear regression using the base-R lm() function. For those not familiar with regression modeling, it is the most basic form of predictive analysis. The overall idea of regression analysis is to examine the predictive power of a variable, i.e. how well of a job does a particular independent variable (predictor) do in predicting the outcome of a dependent variable?\nIf you’ve never conducted a regression analysis before, I’m going to walk you through this process here. Alright, let’s get started.\nExercise 3.1\nCreate an R code chunk and name it modAge\n\nClick for Answer\nSOLUTION\nThis activity should be relatively self explanatory, but here it is:\n{r modAge}\nExercise 3.2\nAbove, I explained the general goals of a regression analysis. The goal is to determine how well a predictor variable explains the outcome of a dependent variable. In this case, we are interested in whether the age of the vampire (variable: ageOfVampire) has explanatory value in predicting how many people a vampire changes into vampires (variable: numberChangedToVamp).\nThe lm() (which stands for linear model) takes the arguments FORMULA and DATA. FORMULA refers to the formula y ~ x, i.e. the dependent variable y (numberChangedToVamp) as a function of the independent variable x (ageOfVampire). DATA refers to the data set in which your variables are saved.\nUsing the lm() function, replace the y and x with the respective variables from above, fill in the data argument in the code chunk below, and save this as an object with the name modAge.\n\n\n... = lm(y ~ x, data = ...)\n\n\n\n\nClick for Answer\nSOLUTION\nWith this model, we are assessing the predictive power of the age of the vampires on how many people the vampires in this data set change to vampires.\n\n\nmodAge =                                     # define object\n  lm(numberChangedToVamp ~ ageOfVampire,     # number changed to vamp as a function of vampire age\n     data = Vampires)                        # supply the data frame in which the variables are saved\n\n\n\nExercise 3.3\nAlright, now we have run a simple linear regression model. The hard part is always interpreting the output that we have here.\nTo have a look at the output of this regression model, you can use the summary() function, with the argument being a linear model. Insert the modAge linear regression into the summary() function.\n\nClick for Answer\nSOLUTION\nWe can get the results of our linear regression model by running the following code chunk.\n\n\nsummary(modAge)          # call summary of the model\n\n\n\nCall:\nlm(formula = numberChangedToVamp ~ ageOfVampire, data = Vampires)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.5447 -3.3155 -0.6979  1.7053 14.8689 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   9.49448    1.29026   7.359 5.77e-11 ***\nageOfVampire -0.01532    0.01424  -1.075    0.285    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.648 on 98 degrees of freedom\nMultiple R-squared:  0.01166,   Adjusted R-squared:  0.00158 \nF-statistic: 1.157 on 1 and 98 DF,  p-value: 0.2848\n\nExercise 3.4\nThe output of the linear regression model gives us important information, namely the intercept and the slope of the respective predictor variable. But what do these actually mean? Well, good question!\nThe INTERCEPT is the y-value when x = 0, so the amount of people vampires at age 0 have changed into vampires.\nThe SLOPE tells us: for every increase of 1 unit from 0, the outcome variable changes (starting from the value of the intercept) by this value. In our case, this means: For every year increase (from 0), i.e. for every year older a vampire becomes, a vampire changes .008 more people into vampires (again, from the intercept).\nNot very intuitive, right? It doesn’t make a lot of sense. A vampire 1 year old probably wouldn’t be changing anyone into anything. How do we fix this?\nWell, to make regression modeling more intuitive, we tend to CENTER variables, which just means we subtract the mean from each data point. Thus, the variable is expressed in terms of how much each data point is ABOVE the mean (positive score) or BELOW the mean (negative score). If a variable is centered, then zero represents the MEAN of the respective variable. We can center variables using the scale() function and adding the argument scale = FALSE.\nYour next task: Using the mutate() function, center the variable ageOfVampire, and save the new data frame as vampDat. Save this code chunk as manipuate data frame.\nHINT You will need to form the scale() function as scale(ageOfVampire, scale = FALSE)\n\nClick for Answer\nSOLUTION\nThis one is a bit tricky. To start off, we know we need the save the data set as vampDat, which we can do relatively easily using the = operator. After that, we need to define the data frame that we want to ‘reach into’, which in this case is the Vampires data frame. We then use the pipe %>% to signal that we want to string functions together. After this, we need the mutate() function. The mutate() function takes the name of the new variable as its first argument. We want to overwrite the ageOfVampire variable in this new data frame, so we just add this name. Then we add the = operator, after which we apply the scale() function given above.\n\n\nvampDat =                            # define object\n  Vampires %>%                       # data\n  mutate(ageOfVampire =              # define NEW VARIABLE (this overrides current age variable)\n           scale(ageOfVampire,       # apply the scale() function\n                 scale = FALSE))     # set scale argument to false, which centers the variable\n\n\n\nExercise 3.5\nNow that we have centered our predictor variable, we can more easily interpret the slopes and intercept. Run another linear model using the same variables, but changing the data frame to vampDat, since this has the newly centered predictor variable ageOfVampire. Save this model as modAge_c.\nHow can we interpret this output?\n\nClick for Answer\nSOLUTION\nLet’s first run the linear model.\n\n\nmodAge_c =                                  # define object\n  lm(numberChangedToVamp ~ ageOfVampire,    # number changed to vamp as a function of vampire age\n     data = vampDat)                        # supply data frame in which the variables are contained\n\nsummary(modAge_c)                           # call model summary\n\n\n\nCall:\nlm(formula = numberChangedToVamp ~ ageOfVampire, data = vampDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.5447 -3.3155 -0.6979  1.7053 14.8689 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   8.20000    0.46478  17.643   <2e-16 ***\nageOfVampire -0.01532    0.01424  -1.075    0.285    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.648 on 98 degrees of freedom\nMultiple R-squared:  0.01166,   Adjusted R-squared:  0.00158 \nF-statistic: 1.157 on 1 and 98 DF,  p-value: 0.2848\n\nThe INTERCEPT is the predicted mean of people changed to vampires when we consider the average age of the vampires in the data set. In other words, vampires in an average age (of our sample)—which is 81.49—are predicted to have changed 8.4 people into vampires. We can check this in a broad way by running the following code as well, which filters the data frame to vampires around the approximate mean age of the sample, and then checking the mean amount of people they have changed to vampires. We should get a value relatively close to the intercept of the new model.\n\n\nVampires %>%                                             # data\n  filter(ageOfVampire > 80 | ageOfVampire < 82) %>%      # select vamps between ages of 80 and 82\n  summarize(mean = mean(numberChangedToVamp),            # receive mean of vamps between ages of 80 and 82\n            sd = sd(numberChangedToVamp))                # receive standard deviation\n\n\n# A tibble: 1 × 2\n   mean    sd\n  <dbl> <dbl>\n1   8.2  4.65\n\nThe SLOPE now tells us that for every increase from 0 (which is NOW the mean of the group) by 1 unit (i.e. by 1 year in this case), the number of vampires changed increases (from the intercept) by this amount (i.e. .008).\n\n\n\n",
      "last_modified": "2022-03-09T21:42:54+01:00"
    },
    {
      "path": "ExercisesUnit7.html",
      "title": "7. Let’s get plotting",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 1.1\nExercise 1.2\nExercise 1.3\nExercise 1.4\n\nExercise 2\nExercise 2.1\nExercise 2.2\nExercise 2.3\nExercise 2.4\n\nExercise 3\nExercise 3.1\nExample 3.2\nExercise 3.3\n\nExercise 4: The Ugly Plot\nAdvanced: Visualizing GAMs using ggplot2\n\nFor (later) reference, you can find here a list of common geom_ functions\nExercise 1\nRun the following code chunk\n\n\n# libraries\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,                                     # data manipulation\n  palmerpenguins                                 # package containing data frame to plot\n)\n\ntheme_set(theme_bw(12))                          # set ggplot2 theme\n\niris = iris                                      # load in iris data frame\nVampires = read_csv(\"./Data/Vampires.csv\")       # load in Vampires data frame\n\n\n\nExercise 1.1\nThe data frame iris contains the two variables Sepal.Length and Sepal.Width. Both variables are continuous, meaning we can make a scatter plot to show the relationship between the two variables. Using Sepal.Length as the x and Sepal.Width as the y, plot these two variables using a scatter plot.\nHINT You will need the function geom_point().\n\nClick for Answer\nSOLUTION\nWhen plotting with ggplot2, we first have to define which data frame contains the two variables. In this case, this is the data frame iris.\n\n\niris %>%                                     # data \n  ggplot(aes(x = Sepal.Length,               # set x value\n             y = Sepal.Width)) +             # set y value\n  geom_point()                               # apply geom_point() function\n\n\n\n\nExercise 1.2\nggplot2 is extremely flexible, and we can plot just about everything we can imagine (and then some). The data frame iris also contains the variable Species (which are the 3 species of iris, namely setosa, versicolor and virginica). Let’s say we would like to focus on finding a plotting method to classify the species. To do this, we could simply color-code the data points according to which species they belong to.\nBuilding off the code from the previous code chunk, color-code the variables according to which species (variable: Species) they belong to.\nHINT Remember, when we want to assign colors (i.e. AESTHETICS) to a geom, we do this via the mapping function (i.e. the aes() function).\n\nClick for Answer\nSOLUTION\nBuilding off the code we have already written, we can assign the colors using the color argument in the aes() function.\n\n\niris %>%                                        # data\n  ggplot(aes(x = Sepal.Length,                  # set x value\n             y = Sepal.Width)) +                # set y value\n  geom_point(aes(color = Species))              # aesthetics: separate colors for SPECIES\n\n\n\n\nNote, play with the color of the plots, see this document.\nExercise 1.3\nUsing the labs() function, change the x axis of the plot to read “Sepal Length”, the y axis to read “Sepal Width” and the title to read “Iris Scatterplot”.\n\nClick for Answer\nSOLUTION\nUsing the labs() function is very intuitive, all we need to do is add the labs() function and specify the x, y and title arguments. REMEMBER when specifying these, the labs need to be in parentheses!\n\n\niris %>%                                      # data\n  ggplot(aes(x = Sepal.Length,                # set x value\n             y = Sepal.Width)) +              # set y value\n  geom_point(aes(color = Species)) +          # aesthetics: separate colors for SPECIES\n  labs(x = \"Sepal Length\",                    # label x axis\n       y = \"Sepal Width\",                     # label y axis\n       title = \"Iris Scatterplot\")            # title of the plot\n\n\n\n\nExercise 1.4\nUsing the ggsave() function, save this plot as “scatterplotIris” using a RELATIVE PATH to the folder Figures. Save the plot as a .png file.\nHINT REMEMBER, we have to save our final plot as an object before saving it! To specify the relative path, you will need the file = argument, i.e. ggplot(OBJECT, file = “./Figure/scatterplotIris.png”)\n\nClick for Answer\nSOLUTION\nTo save a plot, we first need to save this as an object, which the directions specified as “scatterplotIris”. So, we first save the plot using the = operator.\n\n\nscatterplotIris =                           # define object\n  iris %>%                                  # data                         \n  ggplot(aes(x = Sepal.Length,              # set x value\n             y = Sepal.Width)) +            # set y value\n  geom_point(aes(color = Species))          # aesthetics: separate colors for SPECIES\n\n# save object to FIGURES folder and name object boxplotPenguine.png\nggsave(scatterplotIris, file = \"./Figures/boxplotPenguine.png\")      \n\n\n\nExercise 2\nBefore beginning with the following exercises, run the following code:\n\n\npenguins = penguins %>% tibble()           # load in data as a atibble\n\n\n\nExercise 2.1\nTake a look at the penguins data frame (using either view(penguins) or simple penguins). Let us say we are interested in the extent to which the body mass of the penguins (variable: body_mass_g) differs between islands (variable: islands). We would like to plot this using a boxplot.\nIf we were to plot this in base R, the plot would look like the following:\n\n\n# RUN this code to see what the plot looks like in base R\n# you do not need to do anything with the code other than run it\nboxplot(penguins$body_mass_g ~ penguins$island)\n\n\n\n\nWhat is the x variable? What is the y variable? What do we need to enter into our ggplot to recreate this base R plot using ggplot2?\nHINT You will need the geom geom_boxplot\n\nClick for Answer\nSOLUTION\nAs always, we specify our data frame, which in this case is penguins. After that, we need to specify our aesthetics arguments, i.e. the x and y arguments. Since we want to divide the boxplot up by islands, this has to be our x argument, since the x axis shows the different groups (i.e. different islands). The y axis on the other hand shows the body mass of the penguins. After we have defined our aesthetics arguments, we can then simply tell ggplot to plot a boxplot by specifying geom_boxplot(). Easy, right?!\n\n\npenguins %>%                            # data\n  ggplot(aes(x = island,                # x value\n             y = body_mass_g)) +        # y value\n  geom_boxplot()                        # apply the BOXPLOT geom\n\n\n\n\nExercise 2.2\nAlright, so we have now plotted a boxplot. This is great, but boxplots are not necessarily always the best way to visualize data, because the distribution of the groups are not shown. A boxplot only displays the median, and the data’s quartiles. This isn’t always helpful, so we often want to somehow show the distribution of our data. We can very easily do this in ggplot by simply adding the individual data points.\nTo display the individual data points, we can add the geom geom_jitter (which is similar to geom_point(), the only difference being the dots are spread out a little more). Add geom_jitter() to the ggplot code from exercise 2.1.\n\nClick for Answer\nSOLUTION\nThe great thing about ggplot is that we can stack geoms on top of each other, adding layers to our plot. This makes it very simple to create informative plots.\nTo add the individual data points, we can simply add the geom_point() function to the plot we have already created.\n\n\npenguins %>%                               # data\n  ggplot(aes(x = island,                   # set x value\n             y = body_mass_g)) +           # set y value\n  geom_boxplot() +                         # apply BOXPLOT geom\n  geom_jitter()                            # apply JITTER geom (scattered data points)\n\n\n\n\nExercise 2.3\nNow, let’s say that we would like to color code the islands, so that each island on the boxplot has a different color. How could we do this?\nHINT Remember, if we want to specify the ASTHETICS (such as color), we need the aes() function, and in this case we would like to FILL the boxplots with color.\n\nClick for Answer\nSOLUTION\nSince we want to define some type of aesthetic, we need the aes() function. We can EITHER define this in the aes() function in the ggplot() function, or in the geom_boxplot() function (doesn’t make any difference either way). Since we want to fill the boxplots according to the island, we have to specify the fill argument in the aes() function, as seen below.\n\n\npenguins %>%                              # data\n  ggplot(aes(x = island,                  # set x value\n             y = body_mass_g)) +          # set y value\n  geom_boxplot(aes(fill = island)) +      # apply BOXPLOT geom; sep. colors for ISLAND\n  geom_jitter()                           # apply JITTER geom (scattered data points)\n\n\n\n\nExercise 2.4\nUsing the ggsave() function, save this plot as “boxplotPenguine” using a RELATIVE PATH to the folder Figures.\nHINT REMEMBER, we have to save our final plot as an object before saving it! To specify the relative path, you will need the file = argument. Don’t forget the NAME the plot in the file argument!\n\nClick for Answer\nSOLUTION\nTo save a plot, we first need to save this as an object, which the directions specified as “boxplotPenguine”. So, we first save the plot using the = operator.\n\n\nboxplotPenguine =                           # define object\n  penguins %>%                              # data\n  ggplot(aes(x = island,                    # set x value\n             y = body_mass_g)) +            # set y value\n  geom_boxplot(aes(fill = island)) +        # apply BOXPLOT geom; sep. colors for ISLAND\n  geom_jitter()                             # apply JITTER geom (scattered data points)\n\n# save boxplotPenguine object in FIGURES folder and named boxplotPenguine.pdf\nggsave(boxplotPenguine, file = \"./Figures/boxplotPenguine.pdf\")\n\n\n\nExercise 3\nEspecially when we are first having a look at our data, and when we then want to somehow plot our descriptive statistics (e.g. gender, age etc.), many are tempted to use barplots. Barplots, however, are relatively uninformative, and can oftentimes be misleading. In the words of McElreath (2015: 203)\n\nBarplots suck. […] The only problem with barplots is that they have bars. The bars carry only a little information—which way to zero, usually—but greatly clutter the presentation and generate optical illusions.\n\nIt’s therefore better to use other visualization methods such as dotplots, density plots, violin plots, eye or half-eye plots. These types of plots are extremely easy to make in R (even easier than barplots).\nExercise 3.1\nLet’s take our Vampires data frame. We would like to visualize the data distribution of age (variable: ageOfVampire) in our group using a density plot (geom_density()). When plotting a density plot, the aes() function only takes an x = argument.\n\nClick for Answer\nSOLUTION\nWhen visualizing a density plot, we as always need to define which data frame our variable(s) are saved in. In this case, this is the Vampires data frame. We then use the pipe and begin with the ggplot() function. We then need to define our x = argument in the aes() function. After, we simply apply the geom_density() function.\n\n\nVampires %>%                            # data\n  ggplot(aes(x = ageOfVampire)) +       # set x value\n  geom_density()                        # apply DENSITY geom\n\n\n\n\nExample 3.2\nAlright, now let’s say we would like to display the age distribution according to the gender of the vampires. To do this, we can apply the fill argument to the aes() function, and instructing ggplot to plot the ageOfVampire variable, filling the density plots by gender.\nApply the variable gender to the fill argument in the aes() function.\n\nClick for Answer\nSOLUTION\nNow, to plot the density plots according to gender, all we need to do is apply the fill argument to the aes() function.\n\n\nVampires %>%                              # data\n  ggplot(aes(x = ageOfVampire,            # set x value                 \n             fill = gender)) +            # fill density with colors by GENDER\n  geom_density()                          # apply DENSITY geom\n\n\n\n\nExercise 3.3\nBut WAIT! The plots overlap and we can’t see them well. We have several options here—probably the easiest is that we can make the density plots ‘lighter’, so that we can see both plots and their distributions. We do this by applying the alpha argument to the respective geom.\nApply the alpha = .4 argument to the geom_density() function. After, play with changing the .4 to higher / lower (between 0 and 1) to see what this function does.\n\nClick for Answer\nSOLUTION\nTo make the density plots more transparent, we can apply the alpha argument and adjust the degree of transparency.\n\n\nVampires %>%                           # data\n  ggplot(aes(x = ageOfVampire,         # set x value\n             fill = gender)) +         # fill density with colors by GENDER\n  geom_density(alpha = .4)             # apply DENSITY geom; transparency 40%\n\n\n\n\nExercise 4: The Ugly Plot\nHere a list of common geom_ functions: Use this list to test out different geoms on the Vampires, Iris or Penguine data frames.\nWHO CAN MAKE THE UGLIEST PLOT?!\nTake 15-20 minutes and (either alone or in groups) attempt to make the absolut worst, ugliest, horribly looking and utterly vomit-worthy plot you can manage by stacking geoms on top of each other.\nAnd don’t forget to test out different ggplot2 THEMES!!\nSave this plot, USING A RELATIVE PATH, in the Figures folder as a .png file under the name uglyPlot_your initials.png\nSend this to me via E-Mail (mason.wirtz@stud.sbg.ac.at) once you are finished.\nAdvanced: Visualizing GAMs using ggplot2\nWhen working with any type of data, visual analysis should always be your first step. Before deciding on the distribution of a model, it is worth considering whether the nonlinearity of a predictor-outcome relationship is pronounced enough to justify using methods other than linear methods.\nIf you’re ever interested in using generalized additive models (GAMs), it is also entirely possible to visually diagnose whether the data you are dealing with are nonlinear enough to advocate/justify using GAMs.\nLet’s say we are interested in visualizing the nonlinear effects of age of the vampires on the number of people a vampire has changed into vampires, with seperate smooths fitted to gender. We can diagnose whether a GAM is perhaps justified by plotting this using the geom_smooth function, specifying the method as “gam” and the formula as y as a function of the smooth term x. This shows us a relatively linear model, so we might think twice before using a complexer model such as a GAM or GAMM.\n\n\nVampires %>%                               # data\n  ggplot(aes(x = numberChangedToVamp,      # set x value\n             y = ageOfVampire)) +          # set y value\n  geom_point() +                           # apply POINT geom (data points)\n  geom_smooth(aes(color = gender,          # apply SMOOTH geom; sep. color for GENDER\n                  fill = gender),          # fill color by GENDER\n              method = \"gam\",              # smoothing method GAM \n              formula = y ~ s(x)) +        # formula for smoothing function; nonlinear x\n  scale_color_viridis_d(\"gender\") +        # define color scheme\n  scale_fill_viridis_d(\"gender\")           # define color scheme\n\n\n\n\nLet’s take a look at what would justify using a GAM:\n\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  mgcv,                               # GAMs\n  gratia                              # plot GAM\n)\n\nset.seed(4444)                        # set seed for reproducability  \ndat = gamSim(4, n = 400)              # generate nonlinear data with factors\n\n\nFactor `by' variable example\n\ndat %>%                               # data\n  ggplot(aes(x = x2,                  # set x value\n             y = y)) +                # set y value\n  geom_point() +                      # apply POINT geom (data points)\n  geom_smooth(aes(color = fac,        # apply SMOOTH geom; color by FAC\n                  fill = fac),        # fill by FAC\n              method = \"gam\",         # smoothing method GAM \n              formula = y ~ s(x)) +   # formula for smoothing function; nonlinear x\n  scale_color_viridis_d(\"fac\") +      # define color scheme\n  scale_fill_viridis_d(\"fac\")         # define color scheme\n\n\n\n\nWe see very clear nonlinear trends. Let’s compare this to output after we have decided to run a GAM.\n\n\nmodel =                       # define object\n  bam(y ~ s(x2, by = fac),    # y as a nonlinear function of x2; sep. smooths for FAC\n  data = dat                  # data argument\n)\n\ndraw(model) &                 # plot effects, quick and dirty\n  theme_bw()                  # change scheme\n\n\n\n\nGiven there are no extra random effects/factor smooths to be taken into account, this should provide us with the same smooths as shown above.\n\n\n\n",
      "last_modified": "2022-03-09T21:43:07+01:00"
    },
    {
      "path": "ExercisesUnit8.html",
      "title": "8. Reporting and reproducibility",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nThis Study\nResearch Questions\nParticipants\nTasks and Instruments\nStatistical analysis (group work advised)\n\nResults\nRQ1: How can the (socio-)demographics of this vampire sample be characterized?\nRQ2: What background variable(s) predict the amount of humans a vampire changes into a vampire?\n\n\nWhen we conduct a study, we want to report it, right? Of course, our first step might be to publish the study, but what about all that extra, supplementary material? Or what if you would just like to document your work and analysis process in one big document? R Markdown is the way to go!\nIn this report, we are going to report on the Vampires data frame. We are going to outline our results and document our work process as we go.\nOn an important note, the directions in this exercise are very vague—there is a reason for that. While there are, of course, guidelines for reporting, how we choose to report results is often an individual process/decision (i.e. what do we plot? What do we show in the form of a table? Which variables do we plot/describe first?) This exercise is set up in a manner similar to the methods and results section of a paper. I will give you broad guidelines, but now it is your turn to develop an individual process of how you would like to report using R Markdown.\nTake this exercise as a free-for-all. Plot excessively, practice manipulating data and most importantly: ASK QUESTIONS! There are binary factors, categorical factors and numeric factors, so there are a lot of plotting and reporting possibilities. Use this exercise to take what we have learned and apply it to a reporting situation.\nWhile you can work alone for this exercise, I suggest group work to bounce ideas off of one another. It is also a great space to get to know other reporting styles.\nLet’s get started!\nThis Study\nGiven the dearth of empirical research on the background lives of vampires and what influences certain domains of their decision making process (particularly, turning another person into a vampire), a questionnaire study was conducted. The present contribution in particular aims to ascertain the respective influence and predictive power of exploratory background variables on the number of humans vampires have turned into vampires. These results should thus give rise to new research initiatives delving into e.g. socio-affective, psycho-cognitive and background predictor variables of vampires’ decision making processes.\nResearch Questions\nGiven the small number of vampires in comparison to humans, the primary goal of this study was to determine what animates a vampire to change a human into a vampire. The following exploratory research questions will be addressed:\nRQ1: How can the (socio-)demographics of this vampire sample be characterized?\nRQ2: What background variable(s) predict the amount of humans a vampire changes into a vampire?\nThe first research question takes a descriptive approach, mapping out (a) how many cities the average vampire has visited; (b) the number of children the average vampire has and (c) how many people the average vampire has changed into a vampire. These results should shed light on the lives vampires have led hitherto. Several background variables were also collected, i.e. gender (binary; male vs. female, no vampires identified as diverse in this sample), age (numerical), state of living (binary; dead vs. alive—interestingly, the response quote by the dead vampires was unexpectedly high), whether the respective vampire identifies as having fangs (binary; yes vs. no), where the respective vampires was born (categorical; continent), among several other background variables.\nThe second question aims to ascertain how select background variables are statistically related to the number of humans a vampire changes into a vampire.\nParticipants\nTASK: Using descriptive statistics (mean, standard deviation, max., min., etc.), outline the participant group in question. Which variables are important to outline here? Should these be reported using tables? Is there a reason to plot any of the variables? How could we plot some of these variables? Remember, it’s important to visually display your data (even if you don’t publish the plots) so as to get to know your data better!!\nTasks and Instruments\nA questionnaire was used to collect data on the variables in question. Via personal networks and social media, participants were recruited. The questionnaire was administered in a quiet, distraction-free room. In future studies, it would be advisable to conduct such studies via online questionnaire tools such as LimeSurvey, as multiple student assistants suddenly disappeared during the face-to-face data collection process (reason unknown).\nStatistical analysis (group work advised)\nTASK: The inferential goal of this study is to ascertain the respective influence of (several) predictor variable(s) on the amount of humans a vampire has changed into a vampire. What inferential methods could we use to do this? Discuss with a partner!\nDon’t forget to think about variable transformations! E.g. centering variables, standardizing variables etc.\nAfter you have decided on which statistical analysis methods you might want to use, look up packages/functions with which these can be done. Do you need any extra packages? Are there methods included in base R?\nIf you are a novice, there are two simple methods you can use: linear regression or correlation analyses.\nCorrelation analysis: A correlation anaysis does not assess the effect of a predictor variable on a response variable, but rater judges the strength of a relationship between two variables (r value between -1 (perfect NEGATIVE relationship) and 1 (perfect POSITIVE relationship)). For those not yet fit in statistical analysis, this would be a good method to start with. In base R, we can use the cor.test() function.\nLinear regression: This assesses the respective effect of the predictor variable x (or predictor variableS x + x + x…) on the response variable y (numberChangedToVampire). For simple linear regression, we can use the base R function lm()\nResults\nRQ1: How can the (socio-)demographics of this vampire sample be characterized?\nTASK: Using tables, plots and however you feel you can best answer this research questions, report the results that answer this research question. You should present descriptive statistics and/or visual displays of the variables contained in the data set (with the exception of the id variable, of course). Don’t forget to provide short descriptions of your work process, and make sure to comment your code in the respective code chunks!\nRQ2: What background variable(s) predict the amount of humans a vampire changes into a vampire?\nTASK: Using what you discussed in the statistical analyses, do your best to use these methods to assess the respective relationship between predictor variables (your choice which variables you choose) and the amount of humans a vampire changes into a vampire.\n\n\n\n",
      "last_modified": "2022-03-09T21:43:08+01:00"
    },
    {
      "path": "ExercisesUnit9.html",
      "title": "9. You don’t just knit with needles: Knitting in R Markdown",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 1.1\nExercise 1.2\n\nExercise 2\nExercise 2.1\nExercise 2.2\n\n\nExercise 1\nUsing the Knit tab, knit your R Markdown document into a HTML file.\nExercise 1.1\nThe default settings for the HTML output are rather dull…that’s why we sometimes change one thing or another to make the document more readable or other suitable for our needs. Using the number_sections argument, reformat the output code of your report document from exercise 8 to number the sections in the document.\n\nClick for Answer\nSOLUTION\nTo do this, we would need to make sure we have defined the output style: html_document: and then tabbed in, number_sections: true\nExercise 1.2\nUsing the toc argument, reformat the output to include a table of contents.\n\nClick for Answer\nSOLUTION\nTo do this, we would need to make sure we have defined the output style: html_document: and then tabbed in, toc: yes\nExercise 2\nExercise 2.1\nTake at look at the two documents below and have a look at the following output arguments (these are included in the output formats in the first few lines of each document).\nDocuments (raw analysis scripts):\nDocument 1\nDocument 2\nWhat do you think the following output arguments do? How do they change the HTML output of the respective document?\nOutput arguments:\ntoc_float\ncode_folding\nfig_height\ntheme\nhighlight\nExercise 2.2\nThe next several links lead to the HTML outputs (you will have to click on the blue download button in the upper right corner to view the HTML documents).\nDocuments (HTML outputs):\nDocument 1\nDocument 2\nCompare your assumptions about what the respective HTML outputs do with what you see in the documents. How do these documents differ to those you knitted in the previous exercises?\n\n\n\n",
      "last_modified": "2022-03-09T21:43:08+01:00"
    },
    {
      "path": "ggplotScript.html",
      "title": "ggplot2 Script",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\nPPT VISUALIZATIONS\nThis first part of the script visualizes the graphics shown in the Presentation.\n\n\n################################## #\n# ggplot2 script                   #\n################################## #\n\n# PRELIMINARIES ----\n# clear work space\nrm(list = ls())\n\n# libraries\nlibrary(tidyverse)           # load in tidyverse\n\n# set ggplot2 theme\ntheme_set(theme_linedraw(12))\n\n# data\ndiamonds = diamonds          # diamonds data frame\npenguins = penguins\n\n# PLOTS FOR POWERPOINT ----\n# no geoms ----\ndiamonds %>%\n  ggplot(aes(x = price))\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/aesthetics.png\")\n\n# geom_histogram ----\ndiamonds %>%\n  ggplot(aes(x = price)) +\n  geom_histogram()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_histogram.png\")\n\n# geom_density ----\ndiamonds %>%\n  ggplot(aes(x = price)) +\n  geom_density()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_density.png\")\n\n# geom_freqpoly ----\ndiamonds %>%\n  ggplot(aes(x = x)) +\n  geom_freqpoly()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_freqpoly.png\")\n\n# geom_bar ----\ndiamonds %>%\n  ggplot(aes(x = color)) +\n  geom_bar()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_bar.png\")\n\n# geom_point ----\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm)) +\n  geom_point()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point.png\")\n\n# geom_jitter ----\ndiamonds %>%\n  ggplot(aes(x = price,\n             y = carat)) +\n  geom_jitter()\n\n\n\n# geom_smooth ----\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm)) +\n  geom_smooth()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_smooth_gam.png\")\n\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm)) +\n  geom_smooth(method = \"lm\")\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_smooth_lm.png\")\n\n# geom_boxplot ----\ndiamonds %>%\n  ggplot(aes(x = cut,\n             y = carat)) +\n  geom_boxplot()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_boxplot.png\")\n\n# geom_barplot_identity ----\ndiamonds %>%\n  ggplot(aes(x = cut,\n             y = carat)) +\n  geom_bar(stat = \"identity\")\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_barplot_identity.png\")\n\n# geom_violiny ----\ndiamonds %>%\n  ggplot(aes(x = cut,\n             y = carat)) +\n  geom_violin()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_violin.png\")\n\n# geom_point_aesthetics\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm,\n             color = species)) +\n  geom_point()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point_aesthetics1.png\")\n\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm,\n             color = species,\n             shape = species)) +\n  geom_point()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point_aesthetics2.png\")\n\n# geom_point + geom_smooth\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm,\n             color = species)) +\n  geom_point() +\n  geom_smooth()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point_geom_smooth.png\")\n\n# geom_point + geom_smooth + geom_smooth_linear\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm,\n             color = species)) +\n  geom_point() +\n  geom_smooth() +\n  geom_smooth(method = \"lm\",\n              color = \"black\")\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point_geom_smooth_geom_smooth_linear.png\")\n\n# geom_jitter + geom_smooth + color_species\npenguins %>%\n  ggplot(aes(x = species,\n             y = bill_depth_mm,\n             color = species)) +\n  geom_boxplot() +\n  geom_jitter()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/boxplot_jitter_color.png\")\n\n# geom_jitter + geom_smooth + fill_species\npenguins %>%\n  ggplot(aes(x = species,\n             y = bill_depth_mm)) +\n  geom_boxplot(aes(fill = species)) +\n  geom_jitter()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/boxplot_jitter_fill.png\")\n\n# geom_jitter + geom_smooth + fill_species + labs\npenguins %>%\n  ggplot(aes(x = species,\n             y = bill_depth_mm)) +\n  geom_boxplot(aes(fill = species)) +\n  geom_jitter() +\n  labs(x = \"Species\",\n       y = \"Bill Depth (in mm)\",\n       title = \"Bill Depth by Species\",\n       subtitle = \"A cool plot\")\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/boxplot_jitter_labs.png\")\n\n\n\nEXTRA VISUALIZATIONS\nGAMMs\nThe following script shows several different visualization techniques for (a) generalized additive mixed effects models, using the newest packages in the business; and (b) Bayesian mixed effects models, using some tips and tricks I’ve assembled during my own statistical analyses.\nLet’s get started!\nCheck out Stefano’s tidymv package for the difference smooths: https://stefanocoretta.github.io/tidymv/articles/plot-smooths.html\nAnd see Simpson’s gratia package for plotting marginal effects plots of the GAM(M) outputs: https://gavinsimpson.github.io/gratia/ When loading in the gratia package, it will install some new dependency packages, so it might end up updating some older package versions that you have. Simpon’s updates for factor smooths aren’t available from CRAN yet, so if you ever need to plot factor smooths from a non-Guassian model, you will need to load in the gratia package directly from github.\nThis can be done with the following code:\nremotes::install_github(\"gavinsimpson/gratia\")\nIn the case that you install the Github version, make sure to install updates dependency structures as well\nHappy plotting! :)\n\n\n# PRELIMINARIES ----\n# clean workplace\nrm(list = ls())\n\n# libraries\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,        # data manipulation\n  mgcv,             # compute (and simulate) GAM(M)s\n  gratia,           # plot partial effect plots of GAM(M)s using ggplot2\n  tidymv            # plot difference smooths of GAM(M)s using ggplot2\n) \n\n# set ggplot theme\ntheme_set(theme_minimal(12)) \n\n\n\nSIMULATE DATA\nSimulate the data for a GAMM. These data include:\na by = factor (fac)\nrandom effects (four groups; i.e. a–d)\nThe model includes\nNonlinear effect for the variable x2 with different trajectories for variable fac\nfactor smooths with different trajectories for variable fac\n\n\n# Simulate GAM data with factor smooths\n# simulate GAM data with a by factor\ndata = gamSim(4, 400) %>%    \n  \n  # simulate random effects structure\n  mutate(rand = rep(letters[1:4],      \n                    each = 100), \n         rand = as.factor(rand))      \n\n\nFactor `by' variable example\n\nRUN MODEL\n\n\n# nonlinear x2 with diff trajectories for variable `fac`\nmod = gam(y ~ s(x2, by = fac) + \n            \n            # factor smooths with diff trajectories for for variable `fac`\n            s(x2, rand, by = fac, bs = \"fs\", m = 1),  \n          \n          # simulated data\n          data = data)\n\n\n\nMARGINAL EFFECTS\nUsing the draw() function in Simpson’s gratia package, we can plot the marginal effects\n\n\n# get marginal effects (also random effects)\ndraw(mod)\n\n\n\n# only plot the first three marginal effects\n# i.e. this excludes the random effects from the viz\ndraw(mod, \n     select = c(1:3))         \n\n\n\n# see ?draw.gam for more options\n\n\n\nDIFFERENCE SMOOTHS\nUsing the get_smooths_difference() from the tidymv package, we conduct a visual significance test to see whether/when the CIs of the factors 1 and 2 are different\n\n\n# get the differences between factors 1 and 2\nget_smooths_difference(mod,                             \n                       x2,                              \n                       list(fac = c(\"1\", \"2\"))) %>%   \n\n  # plot variable of interest (y and x axes)\n  # and group variable specified in the get_smooths_difference()\n  ggplot(aes(x = x2,                                    \n             y = difference,                           \n             group = group)) +      \n  \n  # plot the ribbon with the lower and upper CIs\n  # and whether the difference between CIs\n  # is significant or not\n  geom_ribbon(aes(ymin = CI_lower,                      \n                  ymax = CI_upper,                      \n                  fill = sig_diff),                     \n              alpha = 0.3) +         \n  \n  # determine color based on whether upper/lower CIs are diff\n  geom_line(aes(colour = sig_diff), size = 1) +    \n  \n  # lightgrey when sig_diff is FALSE, green when TRUE\n  scale_colour_manual(values = \n                        c(\"lightgrey\", \"lightgreen\")) + \n  scale_fill_manual(values = \n                      c(\"lightgrey\", \"lightgreen\")) +   \n  \n  # place line at zero\n  geom_hline(aes(yintercept = 0), \n             colour = \"#8f5f3f\") +                     \n  labs(colour = \"significant\", fill = \"significant\") +\n  labs(x = \"x2\", \n       y = \"Factor 1 minus Factor 2\", \n       title = \"Difference Smooths\") +\n  theme(legend.position = \"right\")\n\n\n\n\nSIMULATE DATA: PLOTTING ON THE RESPONSE SCALE\nIf we were, to say, run a model with a non-Gaussian distribution, we oftentimes want to plot the effects on the response scale. So, let’s say, we compute a mixed-effects model and we want to use a beta distribution (because my values are bound between 0 and 1). The following code shows how we could simulate such data.\n\n\n# Simulate GAM data with factor smooths\n# simulate GAM data with a by factor\ndata_beta = gamSim(4, 400) %>%    \n  \n  # simulate random effects structure\n  mutate(rand = rep(letters[1:4],      \n                    each = 100), \n         rand = as.factor(rand)) %>% \n  \n  # a really bad way to get values\n  # between 0 and 1 \n  mutate(y = plogis(y))\n\n\nFactor `by' variable example\n\nRUN MODEL\n\n\n# nonlinear x2 with diff trajectories for variable `fac`\nmod_beta = gam(y ~ s(x2, by = fac) + \n            \n            # factor smooths with diff trajectories for for variable `fac`\n            s(x2, rand, by = fac, bs = \"fs\", m = 1),  \n            \n            # add beta distribution\n            family = betar(link='logit'),\n            \n            # simulated data\n            data = data_beta)\n\n\n\nMARGINAL EFFECTS\nBut of course, now we want to plot this data using the draw() function in Simpson’s gratia package.\n\n\n# plot on the log-odds scale\ndraw(mod_beta)\n\n\n\n# plot on the log-odds scale \n# without random effects\ndraw(mod_beta, \n     select = c(1:3))\n\n\n\ndraw(mod_beta, \n     \n     # the beta distribution is mapped onto the \n     # log odds space using the logit linking function\n     # the logistic function plogis reverses this\n     fun = plogis, \n     \n     # add the intercept value to all model outputs, \n     # before the transformation (fun) \n     constant = (coef(mod_beta)[1]), \n     \n     # select only the relevant smooths\n     # i.e. excluding random effects\n     select = c(1,2,3))\n\n\n\n\nBAYESIAN MIXED-EFFECTS MODELS\nHere, we see a few cool visualization techniques for displaying the results of Bayesian mixed-effects models.\n\n\n# PRELIMINARIES ----\n# clean workplace\nrm(list = ls())\n\n# libraries\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,            # data manipulation \n  brms,                 # Bayesian model\n  marginaleffects,      # plot regression models\n  ggdist,               # plotting\n  tidybayes,            # plot posterior draws\n  modelr,               # data_grid function\n  ggridges,             # ridge plots\n  ggmcmc                # posterior data frame (long format)\n) \n\n# set ggplot theme\ntheme_set(theme_minimal(12)) \n\n\n\nDATA MANIPULATION\nLoad in data from my dissertation. The data used here are from my PhD, namely L2 socio-indexical interpretations of standard German and Austrian dialect.\n\n\n# READ IN DATA\n# I'm using a full path here (DON'T DO THIS IN REAL LIFE)\n# because I'm drawing data from another working directory \n# the good ol' fashioned \"do as I say, not as I do\"\n# how I am reading the data here is really nasty\ndf_rating = full_join(read_csv(\"~/Documents/R/R Projects/DYNSC/Data/Data sets/rating.csv\"),\n                      read_csv(\"~/Documents/R/R Projects/DYNSC/Data/Data sets/exposure.csv\"), \n                      by = \"id\") %>% \n  \n  # z-score: EXPOSURE\n  mutate(\n    englishExposure = scale(englishExposure),\n    standardExposure = scale(standardExposure), \n    dialectExposure = scale(dialectExposure)\n    )\n\n\n\n# DATA MANIPULATION\n\n# FRIENDLY DF function ----\nfriendlyModFun = function(df_rating){\n  \n  # get friendly rating data ready for model\n  friendlyRating = df_rating %>% \n    \n    # choose only friendly ratings\n    filter(grepl(\"Friendly\", indexChar)) %>% \n    \n    # transform data to between 0-1\n    mutate(rating = rating / 100) %>% \n    \n    # make any 1s .999 and any 0s .0001\n    mutate(rating = ifelse(rating == 1, .999, rating), \n           rating = ifelse(rating == 0, .0001, rating))\n  \n  return(friendlyRating)\n  \n}\n\n\n\nRUN MODEL\n\n\n# rating formula\nformula = rating ~ englishExposure*variety + \n  standardExposure*dialectExposure*variety + \n  (standardExposure + dialectExposure | id) + (0 + occupation | id)\n\n# create friendly data frame\nfriendlyRating = friendlyModFun(df_rating)\n  \n# run friendly model\n# I'm also just using flat priors;\n# wouldn't do that in real life either\nmodFriendly = brm(formula, \n                  data = friendlyRating, \n                  family = Beta())\n\n\n\nPLOT THE EFFECTS\nQuantile dotplot\n“The posterior distribution is visualized here in the form of quantile dotplots. A major advantage in Bayesian inference is to quantify our uncertainty revolving around any given effect, and quantile dotplots allow for frequency-based visualizations from which probabilities can easily be extract (Fernandes et al., 2018; Kay et al., 2016). The idea is to represent the posterior distribution not as one canonical point or interval, but as 100 equally likely points. As such, each point of a given distribution represents 1%, so if there are 7 points stacked on top of each other, then the likelihood of this value is 7%. Similarly, if we are interested in the likelihood of a interval between two values, we can count the dots in the respective interval to receive the probability. Note that the estimates are reported an the log odds scale, since the primary goal of this model visualization and the following model summary is to show the directionality of the respective effects […].” (Wirtz, under review)\n\n\nggs(modFriendly) %>% \n  filter(grepl(\"b_\", Parameter)) %>% \n  ggplot(aes(x = value, \n             y = Parameter)) + \n  stat_dotsinterval(quantiles = 100, \n                    slab_colour = \"firebrick\", \n                    slab_fill = \"firebrick\", \n                    .width = c(.70, .95)) + \n  geom_vline(xintercept = 0, linetype = \"dashed\") + \n  labs(y = \"\") + \n  scale_fill_manual(values = c(\"firebrick\", \"skyblue\")) +\n  labs(x = \"Parameter estimate\", \n       y = \"\") \n\n\n\n\nAnother possibility would be to use slab intervals, like in the following plot:\n\n\nggs(modFriendly) %>% \n  filter(grepl(\"b_\", Parameter)) %>% \n  ggplot(aes(x = value, \n             y = Parameter)) + \n  stat_interval() +\n  stat_pointinterval(.width = c(.66, .95), \n                     position = position_nudge(y = -0.3)) +\n  scale_color_brewer() + \n  geom_vline(xintercept = 0, linetype = \"dashed\") + \n  labs(y = \"\") +\n  labs(x = \"Parameter estimate\", \n       y = \"\") \n\n\n\n\nI’m also quite the fan of ridge plots, which can be plotted using the ggridges package.\n\n\nggs(modFriendly) %>% \n  filter(grepl(\"b_\", Parameter)) %>% \n  ggplot(aes(x = value, \n             y = Parameter)) + \n  geom_density_ridges(fill = \"grey\") + \n  geom_vline(xintercept = 0, linetype = \"dashed\") +\n  labs(x = \"Parameter estimate\",\n       y = \"\") +\n  scale_y_discrete(limits = rev) +\n  theme_ridges() \n\n\n\n\nIf, for example, we would like to plot the differences between standard vs. dialect ratings, we could do this using the marginaleffects package and drawing on the posterior distribution.\n\n\n# friendly model: Standard vs. dialect ratings \nmarginaleffects::predictions(modFriendly, \n                             newdata = datagrid(variety = c(\"Dialect\", \"Standard\"))) %>% \n  posteriordraws() %>% \n  ggplot(aes(x = draw)) +        # to change colors of plots use fill = variety\n  stat_halfeye(alpha = .6) + \n  facet_wrap(~ variety) + \n  labs(x = \"Varietal rating\", \n       y = \"\") + \n  theme(legend.position = \"none\")\n\n\n\n\nThe brms package also offers the conditional_effects() function, which allows us to plot conditional effects quick and dirty. To modify the plot, you can get the drawn upon posterior distribution in the conditional_effects() function and revamp the plot a bit.\n\n\nconditional_effects(modFriendly, \n                    effects = \"standardExposure:variety\",\n                    ndraws = 2000)[[1]] %>% \n  ggplot(aes(x = effect1__, \n             y = estimate__)) + \n  geom_ribbon(aes(ymin = lower__, \n                  ymax = upper__), \n              alpha = .3) +\n  geom_line(size = .8) +\n  facet_wrap(~ effect2__) + \n  labs(x = \"Standard German Exposure\", \n       y = \"Friendliness rating\", \n       title = \"Friendliness ratings:\", \n       subtitle = \"Model predictions\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n",
      "last_modified": "2022-03-09T21:45:52+01:00"
    },
    {
      "path": "index.html",
      "title": "IntRo to RStudio and R Markdown",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\nLet’s get started!\nPrerequisites\nThe first step is to download RStudio. If you have not done so already, you can find the links and the directions on how to do this here.\nUsing this website\nThis website accompanies the workshop. All slides are available on this page, as well as on this workshop’s OSF page. You are also free to check out this website’s repository, which shows the source codes, in case anyone is interested.\nThe hands-on exercises are all available as R scripts under Exercise scripts—the exact same exercises AND THEIR SOLUTIONS (hidden, unless you click the Click for answer button under each exercise) are available under Exercises. All solutions have thorough explanations so you can reference them again and again in the future if need be.\nCheck list\nHere is a summary of all the prepping steps.\n\nDownload RStudio (essential)\n\nCreate an OSF account here (optional)\n\nBrowse the Getting started pages\n\n\n\n",
      "last_modified": "2022-03-09T21:45:53+01:00"
    },
    {
      "path": "Schedule.html",
      "title": "Schedule",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nSchedule\nDay 1. Getting wet in the coding waters: Basics of RStudio\n0. Introductions\n1. Introduction to RStudio\n2. Baby steps: Basics of coding in RStudio, part 1\n3. Baby steps: Basics of coding in RStudio, part 2\n4. The tidier the better: Basics of coding with the Tidyverse\n\nDay 2. Give me an R for reproducibility: Basics of R Markdown\n5. Setting up a project\n6. Code chunks in R Markdown\n7. Let’s get plotting\n8. Reporting and reproducibility\n9. You don’t just knit with needles: Knitting in R Markdown\n10. Fun with coding\n\n\n\nSchedule\nDay 1. Getting wet in the coding waters: Basics of RStudio\n0. Introductions\n(13:00—13:45)\nHellos, introductions\nWhat kind of data are we working with?\nGetting to know the website\n1. Introduction to RStudio\n(13:45—14:15)\nWhich panes exist?\nHow can I read in data?\n2. Baby steps: Basics of coding in RStudio, part 1\n(14:15—15:00)\nVectors\nFactors\nData frames\n3. Baby steps: Basics of coding in RStudio, part 2\n(15:00—16:00)\nObjects\nFunctions\nPackages\n4. The tidier the better: Basics of coding with the Tidyverse\n(16:00—17:00)\nTibbles\nData wrangling with dplyr\nPiping with magritter\nDay 2. Give me an R for reproducibility: Basics of R Markdown\n5. Setting up a project\n(09:00—10:00)\nHow do I create an .Rproj file?\nHow can/should I structure my folders/files?\nRelative/absolute file paths\n6. Code chunks in R Markdown\n(10:00—11:30)\nWhat is a code chunk in R Markdown?\nStructuring code chunks\nLUNCH\n7. Let’s get plotting\n(12:30—14:30)\nPlotting with ggplot2\nSaving ggplots\n8. Reporting and reproducibility\n(14:30—15:30)\nR Markdown syntax\nInline formatting\nBlock-level elements\n9. You don’t just knit with needles: Knitting in R Markdown\n(15:30—16:00)\nKnitting an HTML document\nKnitting a Word document\nUploading/downloading from OSF\n10. Fun with coding\n(16:00—17:00)\nWorking with your own data\nQuestions, individual work\nNote: If you don’t have your own data, send me a short description of your project and I will simulate data similar to the data you will be working with so that you have something to practice!\n\n\n\n",
      "last_modified": "2022-03-09T21:45:53+01:00"
    }
  ],
  "collections": []
}
