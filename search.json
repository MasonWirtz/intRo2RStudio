{
  "articles": [
    {
      "path": "about.html",
      "title": "Preliminaries",
      "description": "Starting information about the workshop\n",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nWorkshop details\nGetting started\nCreate an OSF account (voluntary)\nPrevious knowledge\nTopics\nLanguage\n\nWorkshop details\nThis workshop takes place on the 18. and 19. of MARCH, 2022.\n18. March: 13:00—17:00\n19. March: 09:00—17:00 (11:30—13:00 LUNCH)\nPlace: University of Salzburg, Unipark (Erabzt-Klotz-Straße 1)\nRoom: 3.206\nGetting started\nIn this workshop, we will learn the basics of (a) using the free programming language R; (b) how to work in RStudio; (c) how to write and format reports using R Markdown and (d) how to structure R projects in a manner that eases the workflow when working quantitatively, but also facilitates easy reproducibility of the analyses. The workshop is geared towards PhD students interested in working quantitatively and is freely open to any interested faculty as well as MA students. All parts of the workshop will include hands-on exercises. At the end of the workshop, you will also have free time to use your own data, ask me questions and get feedback.\nCreate an OSF account (voluntary)\nThe second part of this workshop is going to deal with open data and reproducibility. One of the most used open data repositories is the Open Science Framework (OSF). Accounts are, of course, free and easy to set up. Under this link you can find a guide on how to create an account. Feel free to browse the website—take a look at other peoples’ repositories: How do they structure their open data? What trends do you see? Do some structures seem to make more or less sense to you? Of course, you don’t have to do this in preperation for the workshop, but it can certainly never hurt!\nYou won’t explicitely need an OSF account for this workshop, so this step is really entirely up to you. I would, however, highly recommend it—especially because you can store data here. If you create a repository, it is not automatically open to the public. You can store 5GB of data (of whatever type) in a repository, and it is one of the most secure networks for the sciences. You can then create a share-only like or edit link for collaboration. As far as I am aware, there is no limit to the amount of repositories you can create, so you can use this to collaborate—it is absolutely great!\nAs soon as a repository is open to the public, you then have 50GB of storage on the respective project/repository (since the goal here is, after all, open data/open science). We will go through a few walk-throughs of the website and how you can also store more than 5GBs on a private repository, if you should ever need that.\nPrevious knowledge\nIn general, there is no previous knowledge required to partake in this workshop, but very basic experience with R or RStudio is definitely helpful, as we will be covering the basics relatively quickly.\nI highly reccomend, before coming to this workshop, that you read the first chapter of Bodo Winter’s Statistics for Linguists: An Introduction using R if you have not worked with R until this workshop. Even if you don’t work along with the exercises in the book, simply reading the first chapter will give you a feel of what R is as a programming language. And if you are also in need of an introduction to the regression framework, this book is one for you!\nAlternatively, I can highly recommend Michael Franke’s An Introduction to Data Analysis, chapters 2.1–2.3, for a beginning look at R.\nTopics\nParticipants should leave this workshop with surer footing in the following areas:\nBasic coding in RStudio (we will largely use the Tidyverse)\nTypes of variables (vectors, factors, data frames)\nImporting data\nSetting up an R Markdown document\nEnsuring reproducible and understandable code\nStructuring an R project (folders, files, project management etc.)\nUsing OSF (Open Science Framework) to store data\nLanguage\nThe workshop material will be in English, but questions/discussions can be in German.\nSince most of the literature I have read hitherto (and most of the existing literature) on the topics we will be covering in this workshop are in English, I personally feel more comfortable speaking and creating the necessary material in English, as I’m not entirely sure I could explain the concepts with the correct vocabulary in German. This is my own personal shortcoming, and I apologize if this is an inconvenience for anyone.\n\n\n\n",
      "last_modified": "2022-03-04T20:42:11+01:00"
    },
    {
      "path": "DataGeneration.html",
      "title": "Data generation script",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\nThis script shows the code for generating the necessary data frames used in the workshop.\n\n\nlibrary(tidyverse)\n\nVampires =\n  tibble(\n  idVampire = 1:100,\n  gender = rnorm(n = 100, mean = 0, sd = 1),\n  ageOfVampire = abs(round(rnorm(n = 100, mean = 80, sd = 30))),\n  deadOrAlive = rnorm(n = 100, mean = 0, sd = 1),\n  hasFangs = rnorm(n = 100, mean = 0, sd = 1),\n  bornIn = rnorm(n = 100, mean = 5, sd = 2),\n  visitedCities = round(abs(exp(rnorm(n = 100, mean = 3, sd = 1)))),\n  numberOfChildren = round(abs(rnorm(n = 100, mean = 3, sd = 2))),\n  numberChangedToVamp = round(abs(exp(rnorm(n = 100, mean = 2, sd = .5))))\n) %>%\n  mutate(idVampire = as.factor(idVampire),\n         gender = ifelse(gender < 0, \"Male\", \"Female\"),\n         deadOrAlive = ifelse(deadOrAlive < 0, \"Dead\", \"Alive\"),\n         hasFangs = ifelse(hasFangs < 0, \"Yes\", \"No\"),\n         bornIn = ifelse(bornIn < 1, \"Asia\",\n                         ifelse(bornIn >= 1 & bornIn < 2, \"Africa\",\n                                ifelse(bornIn >= 2 & bornIn < 3, \"Europa\",\n                                       ifelse(bornIn >= 3 & bornIn < 4, \"North America\",\n                                              ifelse(bornIn >= 4 & bornIn < 5, \"South America\",\n                                                     ifelse(bornIn >= 5 & bornIn < 6, \"Australia\", \"Antarctica\")))))))\n\nwrite_csv(Vampires, file = \"./Data/Vampires.csv\") # write the file\n\n\n\nExport the mtcars and swiss data frames as a .csv files to upload to the workshop website.\n\n\nwrite_csv(mtcars, file = \"./Data/mtcars.csv\")\n\nwrite_csv(swiss, file = \"./Data/swiss.csv\")\n\n\n\n\n\n\n",
      "last_modified": "2022-03-04T20:42:14+01:00"
    },
    {
      "path": "ExercisesUnit2.html",
      "title": "2. Baby steps: Basics of coding in RStudio, part 1",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3\nExercise 4\nExercise 5\nExercise 6\nExercise 7\n\nExercise 1\nCreate an object (i.e. variable, container) called testObject and store five numbers in it.\n\nClick for Answer\nCreating and storing different types of vectors is one of the most essential skills you will need for using R. These first few exercises may seem really trivial, but I promise, you will use these trivial skills so often that you will quickly realize how not trivial they are.\nSOLUTION\nOkay, so we need an object called testObject. This part is easy enough. All I have to do is type testObject. The tricky part is storing something in the object. In this example, we just need to store five numbers in this object. Let’s go ahead and make our lives easy by just using the numbers 1 through 5. We can store the numbers 1 through 5 in an object in a few different ways. Let’s have a look at those few different ways.\nThe way a beginner thinks would probably be to save the numbers in the object like so:\n\n\ntestObject = c(1, 2, 3, 4, 5)\n\n\n\nThis most certainly isn’t wrong, and we achieved our goal. Good, right? Yes, it is! If you did something similar above, that’s great. It means you’ve gotten a grasp on the basics.\nBut, let’s say we want to be lazy. If I have even ten numbers, typing the number and comma is a lot of work. I don’t like work. So let’s make a our lives a little easier by using the fabulous : that R provides us with to make a sequence of numbers, like so:\n\n\ntestObject = 1:5\n\n\n\nSince we are also not stringing numbers together, but using the sequence operator :, we do not need to concatenate function c()–you can use it if you want, but you don’t need it.\nEverything clear? Hervorragend, then let’s move on to the next exercise.\nExercise 2\nCreate a character vector of your name and save it as the object Name\nHINT: The individual elements of a character vector must be under quotation marks\n\nClick for Answer\nSOLUTION\nI tend to use character vectors quite often (we will hear later in this workshop why), so I find it important to take a little bit of time to get to know them.\nIf we want a character vector consisting of different individual elements, then you know what that means: IT’S CONCATINATE TIME! We need the c() in order to string together different character elements, like so:\n\n\nName = c(\"Mason\", \"Allen\", \"Wirtz\")\n\n\n\nOf course, if you don’t need individual character elements (but I prefer them and oftentimes you also need the individual elements), you can also solve this without concatenating things.\n\n\nName = \"Mason Allen Wirtz\"\n\n\n\nBut, using the c() and creating individual character elements gives us more freedom to play around with the vector. More on this later.\nExercise 3\nCreate a vector named numbers and save the sequence 1–100 in it.\n\nClick for Answer\nSOLUTION\nI hinted about this above: If we want to have a larger data frame, it would take us sooooo long to do c(1, 2, 3, 4, 5, 6, …), I personally would die of boredom. Luckily, we can use the : operator and let R work its magic and create us a sequence of numbers between 1 and 100, namely like so:\n\n\nnumbers = 1:100\n\n\n\nExercise 4\nIn R, we have arithmetic operators (we will go into logical operators later) with which we can do simple math. Below, you can find a list of these, which are all very self-explanatory.\nOperator\nDescription\n+\nAddition\n-\nSubtraction\n*\nMultiplication\n/\nDivision\n^ OR **\nExponentiation\nAdd 1 and 1 together to get two\n\nClick for Answer\nSOLUTION\nI think this one is pretty self-explanatory, but just in case:\n\n\n1 + 1\n\n\n[1] 2\n\nExercise 5\nWe can also add vectors together, provided they are numeric. Add the two vectors below together–why does R throw an error?\n\n\na = 4:9\nb = 10:17\n\n\n\nWhat would we need to do in order to fix this error?\n\nClick for Answer\nSOLUTION\nOnly vectors of the same length can meaningfully be added/subtracted etc. Since vector a contains six values, and vector b eight values, R added the fist six values together of the two vectors. Since vector b is longer than vector a though, the last two numbers in vector b were added to the first two numbers in vector a. Basically, vector b realized, “oh no, there are no more numbers in vector a, what do I do?! Oh, I know, I’ll take the first two numbers of vector a and add them to my own last two values!”. R threw us an error to make us aware of this.\nExercise 6\nCreate two vectors (using whatever numerical values you’d like) under the names a and b (the two variables above will be overwritten) and divide the two vectors.\n\nClick for Answer\nSOLUTION\nNothing we haven’t already seen here. We’ll start with generating two vectors, like so:\n\n\na = 1:100\nb = 101:200\n\n\n\nAnd then let’s go ahead and just divide them by each other. The lovely thing about vectors and being able to save them as objects is that it makes doing simple arithmetic operations like this so easy and readable!\n\n\na/b\n\n\n  [1] 0.00990099 0.01960784 0.02912621 0.03846154 0.04761905\n  [6] 0.05660377 0.06542056 0.07407407 0.08256881 0.09090909\n [11] 0.09909910 0.10714286 0.11504425 0.12280702 0.13043478\n [16] 0.13793103 0.14529915 0.15254237 0.15966387 0.16666667\n [21] 0.17355372 0.18032787 0.18699187 0.19354839 0.20000000\n [26] 0.20634921 0.21259843 0.21875000 0.22480620 0.23076923\n [31] 0.23664122 0.24242424 0.24812030 0.25373134 0.25925926\n [36] 0.26470588 0.27007299 0.27536232 0.28057554 0.28571429\n [41] 0.29078014 0.29577465 0.30069930 0.30555556 0.31034483\n [46] 0.31506849 0.31972789 0.32432432 0.32885906 0.33333333\n [51] 0.33774834 0.34210526 0.34640523 0.35064935 0.35483871\n [56] 0.35897436 0.36305732 0.36708861 0.37106918 0.37500000\n [61] 0.37888199 0.38271605 0.38650307 0.39024390 0.39393939\n [66] 0.39759036 0.40119760 0.40476190 0.40828402 0.41176471\n [71] 0.41520468 0.41860465 0.42196532 0.42528736 0.42857143\n [76] 0.43181818 0.43502825 0.43820225 0.44134078 0.44444444\n [81] 0.44751381 0.45054945 0.45355191 0.45652174 0.45945946\n [86] 0.46236559 0.46524064 0.46808511 0.47089947 0.47368421\n [91] 0.47643979 0.47916667 0.48186528 0.48453608 0.48717949\n [96] 0.48979592 0.49238579 0.49494949 0.49748744 0.50000000\n\nWhat R did here was divide each number in the vector a by the number in the same position in vector b (i.e. 1/101, 2/102, 3/103 etc.), so we should wind up with a vector of 100 values in total.\nExercise 7\nAlright, let’s say we ran an experiment and tested the reaction times of a language learner once a day for seven days. We have the reaction times (these are provided for you, see below), but we want to make a vector with the days of the week.\nCreate a character vector with the days of the week and save it as daysOfTheWeek\n\nreactionTimes = rnorm(n = 7, mean = .25, sd = .1) # you don't need to do anything here\n\ndaysOfTheWeek =\n\n\nClick for Answer\nSOLUTION\nAll we have to do here is string together the days of the week and save it under the object daysOfTheWeek, only this time we have a character vector (similar to what we had with our name).\n\n\nreactionTimes = rnorm(n = 7, mean = .25, sd = .1) # you don't need to do anything here\n\ndaysOfTheWeek = c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\n\n\n\nThere is also a nice little base R function (we will learn more about functions later) called weekdays(), which takes a date as an argument. I put together a few variations of how to generate weekdays using this function, in case anyone ever really needs to add this to a data set. Just run the code lines and have a quick look at the output.\nIt’s probably important to mention here: There is always an elegant solution to any question, and probably an easier way to do it. While typing the whole vector our like in my solution above is easy, these solutions are also quite elegant and easily readable. Just food for thought.\n\n\nweekdays(ISOdate(1, 1, 1:7))\n\n\n[1] \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"   \n[6] \"Saturday\"  \"Sunday\"   \n\nweekdays(Sys.Date()+0:6) # days of the week starting on whatever day today is\n\n\n[1] \"Friday\"    \"Saturday\"  \"Sunday\"    \"Monday\"    \"Tuesday\"  \n[6] \"Wednesday\" \"Thursday\" \n\nweekdays(as.Date(4,\"1970-01-01\",tz=\"GMT\")+0:6)\n\n\n[1] \"Monday\"    \"Tuesday\"   \"Wednesday\" \"Thursday\"  \"Friday\"   \n[6] \"Saturday\"  \"Sunday\"   \n\nWe could then combine these two vectors to create a data frame using the function data.frame() from base R (we will learn more about functions in the next section), like so:\n\n\ndata.frame(daysOfTheWeek, reactionTimes)\n\n\n  daysOfTheWeek reactionTimes\n1        Monday     0.1692618\n2       Tuesday     0.1419377\n3     Wednesday     0.1272184\n4      Thursday     0.1962998\n5        Friday     0.4023177\n6      Saturday     0.2549163\n7        Sunday     0.1241956\n\n\n\n\n",
      "last_modified": "2022-03-04T20:42:16+01:00"
    },
    {
      "path": "ExercisesUnit3.html",
      "title": "3. Baby steps: Basics of coding in RStudio, part 2",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3\nExercise 4\nExercise 5\nExercise 5.1\nExercise 5.2\n\nExercise 6\n\nExercise 1\nSo we’ve gotten to know a few different functions. But what do we do if we don’t know the particular arguments a function takes?\nLet’s image we want to generate some random data coming from a Poisson distribution. The function provided to us is rpois(), which basically means “random numbers from a Poisson distribution”.\nIn the help pane, type in rpois (or type ?rpois in the console). What arguments does the function rpois() take?\n\nClick for Answer\nSOLUTION\n\n\n?rpois\n\n\n\nThe rpois() function takes the arguments n (i.e. number of values that should be generated) and the argument lambda (i.e. the mean and the variance, in other words the expected number of events in a given (time) interval).\nExercise 2\nLet’s get to using the actual functions. You looked up the arguments the rpois() function takes.\nHINT lambda specifies the mean and variance of a count process—basically, it’s the expected number of events/successes in a given interval.\nGenerate 10000 random values from the Poisson distribution with a lambda of 3 and save it under the object Poisson.\n\nClick for Answer\nSOLUTION\nAlright, so in the previous exercise, we had a look at the arguments that the function rpois takes. We know that it takes the argument n (i.e. the number of values that should be generated). The exercise asks us to generate 10000 random values, so this must be our n value. The function also takes the argument lambda, which the exercise tells us should be 3. We then want to save this as an object named Poisson.\nLet’s see how we can do this:\n\n\nPoisson = rpois(n = 10000, lambda = 3)\n\n\n\nExercise 3\nSo, you’ve generated (maybe your first?) Poisson distribution, yay!\nLet’s say we now want to plot the random data we just generated. Go to the help pane and look up the arguments for the function hist(). BUT, instead of plotting the FREQUENCY of each value, we want the PROBABILITY. How would we do this? What argument do we need to adjust?\nHINT The plot that you generate should look similar to this one (but don’t fret if the values are a bit different, we are all generating RANDOM values, after all, so they will differ a bit):\n\n\n# YOU DON'T NEED TO DO ANYTHING HERE\n# THIS CODE BIT GENERATES A SIMILAR PLOT\n# TO THE ONE YOURS SHOULD GENERATE\n\nPoisson = tibble(Poisson = rpois(n = 10000, lambda = 3))\n\nPoisson %>%                                           # data \n  ggplot(aes(x = Poisson,                             # aesthetics \n             y = stat(count / sum(count)))) +         # get probability\n  geom_histogram(binwidth = 1,                        # define binwidth  \n                 color = \"black\") + \n  geom_vline(xintercept = 3,                          # add line at lamba value\n             color = \"red\", \n             alpha = .5,\n             linetype = \"dashed\") + \n  labs(x = \"Count/Number of successes\",               # add plot labels\n       y = \"Probability\",\n       title = \"10000 samples of Pois(lambda = 3)\") + \n  theme_bw()\n\n\n\n\n\nClick for Answer\nSOLUTION\nSo, we want to plot our generated data, not as frequencies, but as probabilities, using the function hist(). Our first step here should be to go ahead and look at the arguments that the function takes. Theoretically, we can change the arguments freq and probability in order to get the probability density of the values. If we change the probability argument, we can change it to true (we can write this as TRUE or T, for short). We can also change the freq argument to FALSE, which throws back the probability density as well, so we should end up with the same plot either way.\n\n\nPoisson = rpois(n = 10000, lambda = 3)           # generate the data again\n\nhist(Poisson, probability = T)                   # set probability to true\nhist(Poisson, freq = F)\n\n\n\n\n(Fun side note: The Poisson distribution is being used more and more in linguistics, since it is the canonical distribution for characterizing count data. If you want to e.g. compute a model where your DV is the number of errors produced, number of dialect realizations in an interaction, number of case markers etc., the Poisson distribution should become your new best friend. Bodo Winter’s book Statistics for Linguists has an entire chapter dedicated to the Poisson distribution, I would definitely recommend a read.)\nExercise 4\nCalculate the mean and standard deviation of the number of people the vampires have changed into vampires. Take a look at the data frame and the names of the data frame—which variable do we need?\nHINT You will need the $ operator.\n\n\nmean()\nsd()\n\n\n\n\nClick for Answer\nSOLUTION\nSince I didn’t specify which variable we are interested in, we would need to search the data frame to find out which variable we need. If we just need to remind ourselves which variable we are interested in, we can do this using the colnames() function, which returns the names of the columns, but no information on what is actually in the columns. If we want to see what is actually in the columns without having to print the entire data frame, we can go ahead and use the head() function.\n\n\ncolnames(Vampires)                 # get column names for Vampires data frame\n\n\n[1] \"idVampire\"           \"gender\"              \"ageOfVampire\"       \n[4] \"deadOrAlive\"         \"hasFangs\"            \"bornIn\"             \n[7] \"visitedCities\"       \"numberOfChildren\"    \"numberChangedToVamp\"\n\nhead(Vampires)                     # see first few rows of Vampires data frame\n\n\n# A tibble: 6 × 9\n  idVampire gender ageOfVampire deadOrAlive hasFangs bornIn       \n      <dbl> <chr>         <dbl> <chr>       <chr>    <chr>        \n1         1 Female           54 Dead        Yes      Australia    \n2         2 Male             67 Dead        No       Antarctica   \n3         3 Female           58 Alive       Yes      Asia         \n4         4 Male            123 Alive       No       Antarctica   \n5         5 Male             55 Dead        Yes      Antarctica   \n6         6 Female           39 Alive       No       North America\n# … with 3 more variables: visitedCities <dbl>,\n#   numberOfChildren <dbl>, numberChangedToVamp <dbl>\n\nAfter exploring the data frame, we should find that the variable numberChangedToVamp is the one we are looking for.\nNow that we know which variable we need, the exercise asks us to calculate the mean and standard deviation. We need the $ operator in order to go into the data frame and select exactly this variable. We will then wrap this in the two functions mean() and sd(), like so:\n\n\nmean(Vampires$numberChangedToVamp)        # get mean of numberChangedToVamp\n\n\n[1] 8.86\n\nsd(Vampires$numberChangedToVamp)          # get SD of numberChangedToVamp\n\n\n[1] 5.05529\n\nExercise 5\nThis exercise is best done in small groups.\nIn the help pane, look up the functions rep(), as.factor() and gl(). Which arguments do these functions take?\nIn the next few steps, we will go through how to create a data frame (this exercise begins here, and we will continue it in the next set of exercises—here, we are just focusing on generating two variables, namely ID and Time, see below for more details).\nWhy, you might ask, are we focusing so much on generating data? For one, it get’s you in the rhythm of looking up the arguments in functions—that’s something you will always have to do. Second, it’s great to know and understand how to generate data. Let’s say, for example, we want to run an a priori power analysis for a mixed effects model to find out how likely we are to find an effect OR to judge how large of a sample we might need. Since a priori power analyses for mixed effects models basically can only be done via computer simulations, we need to be able to generate data and data frames. The following steps are a good exercise in developing this ability. Another plus in being able to generate data is you will be able to write your R scripts before you are finished collecting data in an experiment, i.e. you can just generate similar data to which you are collecting, write your analyses code in advance and once you have your data, you have a whole lot less work. Before you are able to generate data, you won’t really see what you’re missing out on—once you can do it, you won’t know how you ever lived without being able to do this.\nSo, let’s start:\nResearch context: We are interested in whether weekly exposure to the L2 during intensive L2 learning in mid-age (between 25–45) has an effect on reaction times in a Stroop task (i.e. how long it takes a participant to click when the color of the word and the word itself are the same). The participants partake in an intensive language learning course over a 20-week period in the target language community, and we test them once a week. There are 15 participants.\nLet’s generate some data for this!\nExercise 5.1\nTo start, we need to generate an ID variable for the participants (remember, these ID numbers need to be some sort of factors!). That means: We want to generate IDs as factors for 15 participants, where each participant is tested 20 times (i.e. each participant ID has to show up 20 times).\nWhich function can we use to do this (HINT you looked it up in the first part of this task!)?\nSave this as an object under the name ID.\n\nClick for Answer\nSOLUTION\nAlright, we want to generate the ID variable for all participants. Since we have 15 participants, we know we will need the numbers (as factors) 1–15. That part is easy enough. The tricky part is repeating the 1–15 20 times (for each data collection point).\nIf you looked at the required functions in the first part of this exercise, a bell hopefully went off in your mind saying that you can use the gl() function, which stands for “generate levels”. This function generates factor levels, and we need the arguments n (number of levels, so this needs to be 15, since we have 15 participants), and k (which is the number of replications, which needs to be 20, since we have 20 data collection points and need to generate each participant’s ID 20 times). So, we need the following code:\n\n\nID = gl(n = 15, k = 20)      # Create ID variables for 20 data collection times\n\n\n\nExercise 5.2\nAlright, so we have our participant ID variable. Now we need a variable called Time, i.e. 20 data collection points per participant. You will need the function rep(x = ..., times = ...) for this.\n\nTime = rep(x = ???, times = ???)\n\n\nClick for Answer\nSOLUTION\nSo, now things get a bit tricky. We need to generate the sequence 1–20 a total of 15 times (the sequence once for each participant). We were given in the exercise the function rep(), which can take the arguments x (the sequence, so 1–20), and times (i.e. how many times should she sequence be repeated?). Thus, we need to enter the following code:\n\n\nTime = rep(x = 1:20, times = 15)\n\n\n\nBUT, this generates a numeric vector. Time points are not numeric, so we need a factor. We can do this a few different ways. For one, we can use the as.factor() function to transform the entire vector into factors, like so:\n\n\nas.factor(Time)                 # change Time to a factor\n\n\n  [1] 1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1 \n [22] 2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2 \n [43] 3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3 \n [64] 4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4 \n [85] 5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5 \n[106] 6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6 \n[127] 7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7 \n[148] 8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8 \n[169] 9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9 \n[190] 10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10\n[211] 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10 11\n[232] 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10 11 12\n[253] 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10 11 12 13\n[274] 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10 11 12 13 14\n[295] 15 16 17 18 19 20\nLevels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\n\nIf we want to do everything in one step, we can just wrap one function within another, transforming the numeric vector 1:20 into a factor in the first step, like so:\n\n\nTime = rep(x = as.factor(1:20), times = 15)       # repeat 1 through 20 as factors 15 times\nTime                                              # print Time\n\n\n  [1] 1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1 \n [22] 2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2 \n [43] 3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3 \n [64] 4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4 \n [85] 5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5 \n[106] 6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6 \n[127] 7  8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7 \n[148] 8  9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8 \n[169] 9  10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9 \n[190] 10 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10\n[211] 11 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10 11\n[232] 12 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10 11 12\n[253] 13 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10 11 12 13\n[274] 14 15 16 17 18 19 20 1  2  3  4  5  6  7  8  9  10 11 12 13 14\n[295] 15 16 17 18 19 20\nLevels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20\n\nExercise 6\nInstall and load the package reshape2.\n\nClick for Answer\nSOLUTION\nIf you haven’t installed this package before, we need to first install the package before we can actually load it, using the install.packages() function. After that, we need to load in the package using the library() function, like so:\n\n\ninstall.packages(\"reshape2\")                # install package reshape2\nlibrary(reshape2)                           # load in library reshape2\n\n\n\n\n\n\n",
      "last_modified": "2022-03-04T20:42:18+01:00"
    },
    {
      "path": "ExercisesUnit4.html",
      "title": "4. The tidier the better: Basics of coding with the Tidyverse",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3\nExercise 4\nExercise 5\nExercise 5.1\nExercise 5.2\n\nExercise 6 (for experts)\n\nExercise 1\nLoad in the data Vampires (preferably as a tibble using the read_csv() function).\nWe are only interested in the columns idVampire, gender, ageOfVampire and numberOfChildren. Create a new data frame called Vamps including only these columns.\n\nClick for Answer\nSOLUTION\nSince our goal here is to simply subset the data frame and select on certain columns, we can use the function select() from the dplyr package included in the tidyverse. This will allow us to pick and choose which columns we want to subset. We can then assign these subsetted variables to a new object, which the directions ask us to call Vamps. Let’s go ahead and do this:\n\n\nVamps =                                       # define object\n  Vampires %>%                                # data\n  select(idVampire, gender,                   # select variables (i.e. subset data)\n         ageOfVampire, numberOfChildren)\n\n\n\nSince the first three columns we want to subset are in a row (i.e. the first three columns), we can also easily specify 1:3 (i.e. columns 1 through 3), plus the variable numberOfChildren, like so:\n\n\nVamps =                                 # define object\n  Vampires %>%                          # data\n  select(1:3, numberOfChildren)         # select variables (i.e. subset data)\n\n\n\nExercise 2\nCalculate the mean amount of cities the vampires have visited (variable: visitedCities), as well as the standard deviation thereof, using the summarize() function.\n\nClick for Answer\nSOLUTION\nAs always, our first step is to reach into the data frame we are interested in, namely Vampires, and then simply use the summarize function, like so:\n\n\nVampires %>%                                       # dataa\n  summarize(mean = mean(visitedCities),            # calculate mean\n            sd = sd(visitedCities))                # calculate SD\n\n\n# A tibble: 1 × 2\n   mean    sd\n  <dbl> <dbl>\n1  33.4  40.0\n\nExercise 3\nCalculate the mean age of male and female vampires.\nHINT You will need the pipe ( %>% ) to group/stack functions, the group_by function and the summarize function (in that order).\n\nClick for Answer\nSOLUTION\nAlright, so our first step, as always, is to specify which data frame we are interested in. Then we want to group our data frame into two groups, namely male and female, which can be done by using the group_by() function on the variable gender. After that, we need the summarize() function to calculate the mean age (variable: ageOfVampire), like so:\n\n\nVampires %>% \n  \n  # Group the data frame by the gender variable, \n  # which is binary, i.e. only male or female.\n  group_by(gender) %>% \n  \n  # Summarize the grouped data \n  summarize(mean = mean(ageOfVampire))\n\n\n# A tibble: 2 × 2\n  gender  mean\n  <chr>  <dbl>\n1 Female  73.7\n2 Male    74.2\n\nExercise 4\nAlright, now we can get to the fun stuff: Manipulating data.\nTo start off, let’s clean up our environment a bit. We won’t really be needing the Vamps data frame we made earlier, so remove it from your environment using the rm(Vamps) function.\nLet’s say we are interested in whether alive vampires have changed more people into vampires depending on whether they have fangs or not. The variables here that will interest us are deadOrAlive, hasFangs and numberChangedToVamp. There is no need to subset the respective variables, but if you want to for the sake of practice, go ahead.\nWhat is the mean number of people the alive vampires WITH and WITHOUT fangs have turned into vampires?\nHINT You will need the pipe ( %>% ) to group/stack functions, the filter function, the group_by function and the summarize function (in that order).\n\nClick for Answer\nSOLUTION\nThis is pretty tricky, there are three steps we need to go through to get to the answer. Let’s go through this together.\nTo start with, we know that we are only interested in ALIVE vampires, so this means that we need to subset the data frame to home in on only the vampires that are alive. Our variable deadOrAlive tells us whether the vampires are dead or alive, so this is the variable we first need to subset. We do this by using the filter() function (remember, filter is for ROWS and select is for COLUMNS). And we specify we only want ALIVE vampires by using the == operator (REMEMBER, the operator = is for assigning values to an object, == means “is equal to”).\nNow, since we are interested in whether vampires with and without fangs have changed more people to vampires, we need to group our data frame into two groups: vampires WITH fangs and vampires WITHOUT fangs. We can do this by using the group_by() function.\nLastly, we then need the summarize function and specify it to give us the mean of the people the vampires WITH and WITHOUT fangs have changed into vampires.\nWe have an interesting outcome, vampires without fangs have changed more people into vampires on average than vampires with fangs…interesting. Maybe vampires without fangs have a Minderwertigkeitskomplex…?\n\n\nVampires %>% \n  \n  # Filter the data frame so that it \n  # ONLY includes vampires that are ALIVE\n  filter(deadOrAlive == \"Alive\") %>% \n\n  # Group the data frame by the hasFangs variable, \n  # which is binary, i.e. only yes or no. \n  \n  group_by(hasFangs) %>% \n  \n  # Summarize the grouped data \n  summarize(mean = mean(numberChangedToVamp))\n\n\n# A tibble: 2 × 2\n  hasFangs  mean\n  <chr>    <dbl>\n1 No       11.0 \n2 Yes       8.96\n\nExercise 5\nRemember how we started generating data in the previous set of exercises? Let’s go back to that. To remind you, we generated the ID variable using the gl() function (generate levels) and Time variable (data collection points, ranging from point 1 to point 20), using the rep() function.\nIn case you didn’t get to that exercise, run the following code to catch up:\n\n\nID = gl(n = 15, k = 20)               # Create ID variables for 20 data collection times\nTime = rep(x = as.factor(1:20),       # Repeat 1 through 20 as factors 15 times\n           times = 15) \n\n\n\nWe will continue building a data frame—I have generated a new variable for you, namely weeklyExposure, which should be understood as the total number of hours per week participants spend engaging with native speakers. Run the following code to generate this variable.\n\n\n# RUN THE FOLLOWING CODE CHUNK\n# YOU DON'T NEED TO DO ANYTHING \n# OTHER THAN RUN THE CHUNK\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  reshape2                                        # load reshape2 library; reshape data\n)\n\nweeklyExposure = replicate(20,                    # create expo. increasing values\n                           rexp(n = 15, \n                                rate = .05)) \nweeklyExposure = weeklyExposure %>%               # bound at 0 and 80\n  melt() %>% \n  mutate(weeklyExposure = ifelse(weeklyExposure %in% \"value\" > 80, 80, weeklyExposure),\n         weeklyExposure = ifelse(weeklyExposure %in% \"value\" < 0, 0, weeklyExposure),\n         weeklyExposure = round(weeklyExposure, digits = 2)) %>% \n  select(weeklyExposure)\n\n\n\nExercise 5.1\nNow, let’s combine these three variables into a single data frame. Use the function tibble(). Please save this tibble under the object name df.\n\nClick for Answer\nSOLUTION\n\n\ndf =                                    # data\n  tibble(ID, Time, weeklyExposure)      # create tibble of variables\n\n\n\nExercise 5.2\nWe would like to have a new variable in this data frame that we make using the contents of the other variables.\nOur new variable should be the weeklyExposure variable log transformed. This variable should be added to the data frame df. Call this new variable logWeeklyExposure.\nHINT To add a new variable to a data frame within the tidyverse framework, we need the mutate() function. To log transform a variable, we need the log() function.\n\nClick for Answer\nSOLUTION\nTo create a new variable, we need the mutate() function. We can then specify how we would like to mutate the contents of a variable in the data frame. Since we simply want to log transform the weeklyExposure variable, we just need to apply the log() function to the weeklyExposure variable.\n\n\ndf =                                       # define object\n  df %>%                                   # data\n  mutate(logWeeklyExposure =               # create NEW variable \n           log(weeklyExposure))            # define TERMS for new variable\n\n# Check df to make sure we got this new variable \ndf\n\n\n# A tibble: 300 × 4\n   ID    Time  weeklyExposure logWeeklyExposure\n   <fct> <fct>          <dbl>             <dbl>\n 1 1     1               3.14              1.14\n 2 1     2              16.6               2.81\n 3 1     3              69.6               4.24\n 4 1     4              58.4               4.07\n 5 1     5              18.4               2.91\n 6 1     6               3.26              1.18\n 7 1     7              31.0               3.43\n 8 1     8              10.6               2.36\n 9 1     9              13.1               2.57\n10 1     10              5.2               1.65\n# … with 290 more rows\n\nExercise 6 (for experts)\nAlright, you’ve done well until now? Great! Let’s take on a harder task. Before you start, look up the arguments for the function ungroup().\nLet’s say we had participants complete several versions of a C Test (a language assessment test in which participants have to complete words—this has been shown to strongly correlate with participants’ general language proficiency, cf. Raatz & Klein–Braley [2002]). Since no two tests are typically exactly the same, even after pilot testing (that is, without conducting large-scale psycho-metric validity screenings), we tend to correct for the possible differences in the tasks statistically. We can correct for differences (to help ensure better comparability) between the versions of the C Test by subtracting or adding the deviation of each version’s mean count from the overall mean count for each individual score.\nLet me generate some data for you that replicates this situation:\n\n\n# RUN THE FOLLOWING CODE CHUNK\n\nCTest_df =                                                          # define object\n  tibble(Version = gl(n = 3, k = 20),                               # generate data\n         CTest = c(round(abs(rnorm(n = 20, mean = 17, sd = 4))),    # generate CTest 1\n                 round(abs(rnorm(n = 20, mean = 19, sd = 4))),      # generate CTest 2\n                 round(abs(rnorm(n = 20, mean = 20, sd = 4))))      # generate CTest 3\n) %>% \n  mutate(CTest = ifelse(CTest > 30, 30, CTest),                     # delete wild devs\n         CTest = ifelse(CTest < 0, 0, CTest)) \n\n# Let's have a look\nCTest_df\n\n\n# A tibble: 60 × 2\n   Version CTest\n   <fct>   <dbl>\n 1 1          21\n 2 1          20\n 3 1          14\n 4 1          13\n 5 1          10\n 6 1          16\n 7 1          21\n 8 1          14\n 9 1          12\n10 1          16\n# … with 50 more rows\n\nCTest_df %>% \n  group_by(Version) %>% \n  summarize_at(.vars = \"CTest\", \n               .funs = c(\"max\", \"min\", \"mean\", \"sd\"))\n\n\n# A tibble: 3 × 5\n  Version   max   min  mean    sd\n  <fct>   <dbl> <dbl> <dbl> <dbl>\n1 1          21     8  15.3  3.83\n2 2          27    13  18.7  4.03\n3 3          27     9  19.2  4.63\n\nSo, now we have a data frame with the version of the C Test (Version) and each participant’s score on the C Tests (CTest).\nAdjust the variable CTest by subtracting or adding the difference of each C Test version’s mean score from the overall mean score of the C Tests from or to each individual score.\nHINT You will need to (or can, there are other ways to solve this) use the following functions in the given order: group_by(), mutate(), ungroup() and mutate()\n\nClick for Answer\nSOLUTION\nSee the commented code below for the solution\n\n\nCTest_df %>% \n  \n  # First we need to group by version, \n  # since we need the mean of each \n  # VERSION of the CTest\n  group_by(Version) %>% \n  \n  # Now we create a NEW variable called \n  # CTestMean, which gives us the mean of \n  # each version\n  mutate(CTestMean = mean(CTest)) %>% \n  \n  # We haven't seen this function yet, \n  # but what it does is the exact opposite \n  # of the group_by() function, \n  # but instead of grouping the different \n  # levels of a factor, it ungroups them \n  # to give us back the actual data frame, \n  # just now with the new variable \n  # (i.e. CTestMean) we just created\n  ungroup() %>% \n  \n  # Now we need to create a few different variables: \n  # We need the OVERALL mean, i.e. the mean of ALL the \n  # C Test scores; We need the difference between the \n  # OVERALL mean score and the mean scores of each \n  # version of the C test. We then change the original \n  # CTest variable by adding the difference (positive or \n  # negative) to each individual CTest score\n  mutate(CTestMean_overall = mean(CTestMean), \n         CTestMean_difference = CTestMean_overall - CTestMean, \n         CTest = CTest + CTestMean_difference) %>% \n  \n  # Now we just get rid of the extra noise variables \n  # that we needed to calculate the adjusted C Test scores\n  select(-c(CTestMean, CTestMean_overall, CTestMean_difference))\n\n\n# A tibble: 60 × 2\n   Version CTest\n   <fct>   <dbl>\n 1 1        23.4\n 2 1        22.4\n 3 1        16.4\n 4 1        15.4\n 5 1        12.4\n 6 1        18.4\n 7 1        23.4\n 8 1        16.4\n 9 1        14.4\n10 1        18.4\n# … with 50 more rows\n\n\n\n\n",
      "last_modified": "2022-03-04T20:42:21+01:00"
    },
    {
      "path": "ExercisesUnit5.html",
      "title": "5. Setting up a project",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 2.1\nExercise 2.2\nExercise 2.3\nExercise 2.4 (Experts)\n\n\nExercise 1\nDownload Exercise script 5 from the workshop website. Save this script in the script folder we created in our new project structure.\nOn the workshop website, download the data frame mtcars and save this in the data folder we created in our new project structure.\nUsing the read_csv() function, load the data frame mtcars into your global environment and save this data frame under the variable name cars. Remember to use a RELATIVE PATH when loading in this data.\nHINT: Don’t forget to put the call in parentheses, and don’t forget the .\n\nClick for Answer\nSOLUTION\nIf we use the read_csv function, we are loading in our data as a tibble, which is really neat (thanks to the tidyverse package(s)). When we read in data from other folders, i.e. from places that are not in the same folder that our script is saved, we need to define the RELATIVE path, which in this case is \"./Data/mtcars.csv\". Since this data is saved in the Data folder, but our script is in the Script folder, we need to jump OUT of the Scripts folder (which is what the . does), and then jump INTO the Data folder (which is what the /Data/) does. Once we have defined this as our RELATIVE path, we can then enter the name of the data frame we want to load (which is mtcars.csv).\n\n\ncars = read_csv(\"./Data/mtcars.csv\")\n\n\n\nExercise 2\nWhen dealing with data, we oftentimes have functions that we write ourselves, because we use them over and over again. For example, if you used a questionnaire and formed items in the negative, you need to reverse this scale. An easy way to do this is to write a function that you can then use on all the items formulated in the reverse.\nExercise 2.1\nCreate a new folder in our folder structure called Functions (you can do this on your regular user system, i.e. how you would normally create a new folder). Make sure this folder is in the R you ready folder structure.\nDownload the script from the workshop website called reverseItems_Functions.R from the Exercise scripts drop-down pane. Save this script (saved under THE SAME NAME) in the functions folder.\nExercise 2.2\nOnce we have the functions saved in the Functions folder, we can use the lovely source() function to call up these functions and use them in a new script. I am a fan of the source() function (and maybe even overuse it…). It takes as its argument a RELATIVE path to an .R file.\nSource the reverseItems_Functions.R file that you saved in the Functions folder, using the RELATIVE path to this .R document. DON’T FORGET THE PARENTHESES!!\n\nClick for Answer\nUsing the relative path, we can source in the functions (and the data frame I included in this script). The source function runs and loads the script in its entirety, so if you created variables, data frames etc. in this script, those will be loaded along with the functions you wrote.\n\n\nsource(\"./Functions/reverseItems_Functions.R\")\n\n\n\nExercise 2.3\nLook at the variable item_6.3 using the call df_items$item_6.3. Then use the linkScaleRev6 function on the variable item_6.3. What did this function do?\n\nClick for Answer\nYou guessed it, this home-made function reversed the scale, turning 1s into 6s, 2s into 5s, and so forth. Isn’t that practical?!\nExercise 2.4 (Experts)\nTake a look at the reverseItems_Functions.R document and the functions I wrote. Write a function that reverses 7-scale items using the ifelse statement. Call this function linkScaleRev7 that takes the argument of an item\n\nClick for Answer\nIf you understood the functions I wrote, this activity shouldn’t be all that challenging :) All you need to do is add an extra ifelse() function to the mix, so that the entire scale is reversed.\n\n\n# reverse a 6-scale item ----\nlinkScaleRev7 =\n  function(item){\n    ifelse(item == 1, 7,\n           ifelse(item == 2, 6,\n                  ifelse(item == 3, 5,\n                         ifelse(item == 4, 4,\n                                ifelse(item == 5, 3,\n                                       ifelse(item == 6, 2, \n                                              ifelse(item == 7, 1, NA)))))))\n  }\n\n\n\n\n\n\n",
      "last_modified": "2022-03-04T20:42:21+01:00"
    },
    {
      "path": "ExercisesUnit6.html",
      "title": "6. Code chunks in R Markdown",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 2\nExercise 3 (intermediate level)\nExercise 3.1\nExercise 3.2\nExercise 3.3\nExercise 3.4\nExercise 3.5\n\n\nExercise 1\nCreate a new R Markdown document and name it “Exercise 6”. Delete the example content in the markdown document (from line 12 and down). Insert a new R chunk by clicking on the Insert button in the editor toolbar (this is the button with a white C in a green square) and choosing R.\nImport the Vampires.csv data set in this chunk using the read_csv() function and save this under the object Vampires. Don’t forget that this data frame should now be in our Data folder!!! Write the relative path in the read_csv() function accordingly!\n\nClick for Answer\nSOLUTION\nBy inserting a code chunk, we are effectively structuring our code in a readable manner and in a way that makes following what our process of analysis is easier. When you look back at your code after a time away from it, it is also much easier to understand what you yourself were thinking when coding. To read in the data frame we are interested in, we do this in our code chunks exactly the same way as we did when working with regular .R documents.\n\n\nVampires = read_csv(\"./Data/Vampires.csv\")         # read in data with a relative path\n\n\n\nExercise 2\nCreate a new code chunk using the Insert button in RStudio. In your new code chunk, complete the following exercise:\nUsing the help bar (or console), look up the arguments of the ifelse() function. What arguments does it take?\nUse the ifelse() function to create a new categorical variable called VampOld: All vampires older than 100 should be categorized as Old, all vampires younger than 100 should be categorized as Young.\nHINT You will need the mutate() function and the ifelse() function.\n\nClick for Answer\nSOLUTION\nSince we are interested in creating a new variable, this should tell us immediately that we need the mutate() function. In the mutate() function, we need to define our new variable VampOld.\nOnce we have defined the new variable, we need to define what should be included in the new variable. Since we want to categorize the age variable (which we really wouldn’t ever want to do in real life, but for practice, it’s an easy example), we can use the ifelse() statement, which first takes an argument to evaluate. The argument to evaluate we need to supply the function with is “if the vampire is older than 100…”, which we can do using the variable ageOfVampire and the > operator. Once we have supplied the ‘if’ argument, we need the ‘then do’ argument, i.e. what needs to happen when this argument is true? In this case, all vampires older than 100 should be categorized as ‘old’, so we supply the function with ‘old’. The final argument in the function takes the ‘else’ part, i.e. what happens when the first argument is false? Since we just want to categorize the variable into old and young, if the vampire is not old, then they must be young, so we supply the final argument with the character value ‘young’.\n\n\nVampires =                                  # define object              \n  Vampires %>%                              # data\n  mutate(VampOld =                          # define NEW VARIABLE\n           ifelse(ageOfVampire > 100,       # TEST (the \"if\" argument)\n                  \"Old\",                    # if the test is TRUE, change to OLD\n                  \"Young\"))                 # if the test is FALSE, change to YOUNG\n\n\n\nExercise 3 (intermediate level)\nYou can name R chunks in R Markdown, which is practical when structuring your analysis process. This can be done by writing a name beside the ` r at the top of the chunk, e.g. as follows\n\n\n# This is an example code chunk NAMED \"example\"\n\n\n\nWe are going to run a simple linear regression using the base-R lm() function. For those not familiar with regression modeling, it is the most basic form of predictive analysis. The overall idea of regression analysis is to examine the predictive power of a variable, i.e. how well of a job does a particular independent variable (predictor) do in predicting the outcome of a dependent variable?\nIf you’ve never conducted a regression analysis before, I’m going to walk you through this process here. Alright, let’s get started.\nExercise 3.1\nCreate an R code chunk and name it modAge\n\nClick for Answer\nSOLUTION\nThis activity should be relatively self explanatory, but here it is:\n{r modAge}\nExercise 3.2\nAbove, I explained the general goals of a regression analysis. The goal is to determine how well a predictor variable explains the outcome of a dependent variable. In this case, we are interested in whether the age of the vampire (variable: ageOfVampire) has explanatory value in predicting how many people a vampire changes into vampires (variable: numberChangedToVamp).\nThe lm() (which stands for linear model) takes the arguments FORMULA and DATA. FORMULA refers to the formula y ~ x, i.e. the dependent variable y (numberChangedToVamp) as a function of the independent variable x (ageOfVampire). DATA refers to the data set in which your variables are saved.\nUsing the lm() function, replace the y and x with the respective variables from above, fill in the data argument in the code chunk below, and save this as an object with the name modAge.\n\n\n... = lm(y ~ x, data = ...)\n\n\n\n\nClick for Answer\nSOLUTION\nWith this model, we are assessing the predictive power of the age of the vampires on how many people the vampires in this data set change to vampires.\n\n\nmodAge =                                     # define object\n  lm(numberChangedToVamp ~ ageOfVampire,     # number changed to vamp as a function of vampire age\n     data = Vampires)                        # supply the data frame in which the variables are saved\n\n\n\nExercise 3.3\nAlright, now we have run a simple linear regression model. The hard part is always interpreting the output that we have here.\nTo have a look at the output of this regression model, you can use the summary() function, with the argument being a linear model. Insert the modAge linear regression into the summary() function.\n\nClick for Answer\nSOLUTION\nWe can get the results of our linear regression model by running the following code chunk.\n\n\nsummary(modAge)          # call summary of the model\n\n\n\nCall:\nlm(formula = numberChangedToVamp ~ ageOfVampire, data = Vampires)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8882 -3.8348 -0.8844  2.1492 20.1860 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  8.765389   1.404782   6.240 1.12e-08 ***\nageOfVampire 0.001279   0.017710   0.072    0.943    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.081 on 98 degrees of freedom\nMultiple R-squared:  5.325e-05, Adjusted R-squared:  -0.01015 \nF-statistic: 0.005219 on 1 and 98 DF,  p-value: 0.9426\n\nExercise 3.4\nThe output of the linear regression model gives us important information, namely the intercept and the slope of the respective predictor variable. But what do these actually mean? Well, good question!\nThe INTERCEPT is the y-value when x = 0, so the amount of people vampires at age 0 have changed into vampires.\nThe SLOPE tells us: for every increase of 1 unit from 0, the outcome variable changes (starting from the value of the intercept) by this value. In our case, this means: For every year increase (from 0), i.e. for every year older a vampire becomes, a vampire changes .008 more people into vampires (again, from the intercept).\nNot very intuitive, right? It doesn’t make a lot of sense. A vampire 1 year old probably wouldn’t be changing anyone into anything. How do we fix this?\nWell, to make regression modeling more intuitive, we tend to CENTER variables, which just means we subtract the mean from each data point. Thus, the variable is expressed in terms of how much each data point is ABOVE the mean (positive score) or BELOW the mean (negative score). If a variable is centered, then zero represents the MEAN of the respective variable. We can center variables using the scale() function and adding the argument scale = FALSE.\nYour next task: Using the mutate() function, center the variable ageOfVampire, and save the new data frame as vampDat. Save this code chunk as manipuate data frame.\nHINT You will need to form the scale() function as scale(ageOfVampire, scale = FALSE)\n\nClick for Answer\nSOLUTION\nThis one is a bit tricky. To start off, we know we need the save the data set as vampDat, which we can do relatively easily using the = operator. After that, we need to define the data frame that we want to ‘reach into’, which in this case is the Vampires data frame. We then use the pipe %>% to signal that we want to string functions together. After this, we need the mutate() function. The mutate() function takes the name of the new variable as its first argument. We want to overwrite the ageOfVampire variable in this new data frame, so we just add this name. Then we add the = operator, after which we apply the scale() function given above.\n\n\nvampDat =                            # define object\n  Vampires %>%                       # data\n  mutate(ageOfVampire =              # define NEW VARIABLE (this overrides current age variable)\n           scale(ageOfVampire,       # apply the scale() function\n                 scale = FALSE))     # set scale argument to false, which centers the variable\n\n\n\nExercise 3.5\nNow that we have centered our predictor variable, we can more easily interpret the slopes and intercept. Run another linear model using the same variables, but changing the data frame to vampDat, since this has the newly centered predictor variable ageOfVampire. Save this model as modAge_c.\nHow can we interpret this output?\n\nClick for Answer\nSOLUTION\nLet’s first run the linear model.\n\n\nmodAge_c =                                  # define object\n  lm(numberChangedToVamp ~ ageOfVampire,    # number changed to vamp as a function of vampire age\n     data = vampDat)                        # supply data frame in which the variables are contained\n\nsummary(modAge_c)                           # call model summary\n\n\n\nCall:\nlm(formula = numberChangedToVamp ~ ageOfVampire, data = vampDat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8882 -3.8348 -0.8844  2.1492 20.1860 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  8.860000   0.508088  17.438   <2e-16 ***\nageOfVampire 0.001279   0.017710   0.072    0.943    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.081 on 98 degrees of freedom\nMultiple R-squared:  5.325e-05, Adjusted R-squared:  -0.01015 \nF-statistic: 0.005219 on 1 and 98 DF,  p-value: 0.9426\n\nThe INTERCEPT is the predicted mean of people changed to vampires when we consider the average age of the vampires in the data set. In other words, vampires in an average age (of our sample)—which is 81.49—are predicted to have changed 8.4 people into vampires. We can check this in a broad way by running the following code as well, which filters the data frame to vampires around the approximate mean age of the sample, and then checking the mean amount of people they have changed to vampires. We should get a value relatively close to the intercept of the new model.\n\n\nVampires %>%                                             # data\n  filter(ageOfVampire > 80 | ageOfVampire < 82) %>%      # select vamps between ages of 80 and 82\n  summarize(mean = mean(numberChangedToVamp),            # receive mean of vamps between ages of 80 and 82\n            sd = sd(numberChangedToVamp))                # receive standard deviation\n\n\n# A tibble: 1 × 2\n   mean    sd\n  <dbl> <dbl>\n1  8.86  5.06\n\nThe SLOPE now tells us that for every increase from 0 (which is NOW the mean of the group) by 1 unit (i.e. by 1 year in this case), the number of vampires changed increases (from the intercept) by this amount (i.e. .008).\n\n\n\n",
      "last_modified": "2022-03-04T20:42:22+01:00"
    },
    {
      "path": "ExercisesUnit7.html",
      "title": "7. Let’s get plotting",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 1.1\nExercise 1.2\nExercise 1.3\nExercise 1.4\n\nExercise 2\nExercise 2.1\nExercise 2.2\nExercise 2.3\nExercise 2.4\n\nExercise 3\nExercise 3.1\nExample 3.2\nExercise 3.3\n\nExercise 4: The Ugly Plot\nAdvanced: Visualizing GAMs using ggplot2\n\nFor (later) reference, you can find here a list of common geom_ functions\nExercise 1\nRun the following code chunk\n\n\n# libraries\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  tidyverse,                                     # data manipulation\n  palmerpenguins                                 # package containing data frame to plot\n)\n\ntheme_set(theme_bw(12))                          # set ggplot2 theme\n\niris = iris                                      # load in iris data frame\nVampires = read_csv(\"./Data/Vampires.csv\")       # load in Vampires data frame\n\n\n\nExercise 1.1\nThe data frame iris contains the two variables Sepal.Length and Sepal.Width. Both variables are continuous, meaning we can make a scatter plot to show the relationship between the two variables. Using Sepal.Length as the x and Sepal.Width as the y, plot these two variables using a scatter plot.\nHINT You will need the function geom_point().\n\nClick for Answer\nSOLUTION\nWhen plotting with ggplot2, we first have to define which data frame contains the two variables. In this case, this is the data frame iris.\n\n\niris %>%                                     # data \n  ggplot(aes(x = Sepal.Length,               # set x value\n             y = Sepal.Width)) +             # set y value\n  geom_point()                               # apply geom_point() function\n\n\n\n\nExercise 1.2\nggplot2 is extremely flexible, and we can plot just about everything we can imagine (and then some). The data frame iris also contains the variable Species (which are the 3 species of iris, namely setosa, versicolor and virginica). Let’s say we would like to focus on finding a plotting method to classify the species. To do this, we could simply color-code the data points according to which species they belong to.\nBuilding off the code from the previous code chunk, color-code the variables according to which species (variable: Species) they belong to.\nHINT Remember, when we want to assign colors (i.e. AESTHETICS) to a geom, we do this via the mapping function (i.e. the aes() function).\n\nClick for Answer\nSOLUTION\nBuilding off the code we have already written, we can assign the colors using the color argument in the aes() function.\n\n\niris %>%                                        # data\n  ggplot(aes(x = Sepal.Length,                  # set x value\n             y = Sepal.Width)) +                # set y value\n  geom_point(aes(color = Species))              # aesthetics: separate colors for SPECIES\n\n\n\n\nNote, play with the color of the plots, see this document.\nExercise 1.3\nUsing the labs() function, change the x axis of the plot to read “Sepal Length”, the y axis to read “Sepal Width” and the title to read “Iris Scatterplot”.\n\nClick for Answer\nSOLUTION\nUsing the labs() function is very intuitive, all we need to do is add the labs() function and specify the x, y and title arguments. REMEMBER when specifying these, the labs need to be in parentheses!\n\n\niris %>%                                      # data\n  ggplot(aes(x = Sepal.Length,                # set x value\n             y = Sepal.Width)) +              # set y value\n  geom_point(aes(color = Species)) +          # aesthetics: separate colors for SPECIES\n  labs(x = \"Sepal Length\",                    # label x axis\n       y = \"Sepal Width\",                     # label y axis\n       title = \"Iris Scatterplot\")            # title of the plot\n\n\n\n\nExercise 1.4\nUsing the ggsave() function, save this plot as “scatterplotIris” using a RELATIVE PATH to the folder Figures. Save the plot as a .png file.\nHINT REMEMBER, we have to save our final plot as an object before saving it! To specify the relative path, you will need the file = argument, i.e. ggplot(OBJECT, file = “./Figure/scatterplotIris.png”)\n\nClick for Answer\nSOLUTION\nTo save a plot, we first need to save this as an object, which the directions specified as “scatterplotIris”. So, we first save the plot using the = operator.\n\n\nscatterplotIris =                           # define object\n  iris %>%                                  # data                         \n  ggplot(aes(x = Sepal.Length,              # set x value\n             y = Sepal.Width)) +            # set y value\n  geom_point(aes(color = Species))          # aesthetics: separate colors for SPECIES\n\n# save object to FIGURES folder and name object boxplotPenguine.png\nggsave(scatterplotIris, file = \"./Figures/boxplotPenguine.png\")      \n\n\n\nExercise 2\nBefore beginning with the following exercises, run the following code:\n\n\npenguins = penguins %>% tibble()           # load in data as a atibble\n\n\n\nExercise 2.1\nTake a look at the penguins data frame (using either view(penguins) or simple penguins). Let us say we are interested in the extent to which the body mass of the penguins (variable: body_mass_g) differs between islands (variable: islands). We would like to plot this using a boxplot.\nIf we were to plot this in base R, the plot would look like the following:\n\n\n# RUN this code to see what the plot looks like in base R\n# you do not need to do anything with the code other than run it\nboxplot(penguins$body_mass_g ~ penguins$island)\n\n\n\n\nWhat is the x variable? What is the y variable? What do we need to enter into our ggplot to recreate this base R plot using ggplot2?\nHINT You will need the geom geom_boxplot\n\nClick for Answer\nSOLUTION\nAs always, we specify our data frame, which in this case is penguins. After that, we need to specify our aesthetics arguments, i.e. the x and y arguments. Since we want to divide the boxplot up by islands, this has to be our x argument, since the x axis shows the different groups (i.e. different islands). The y axis on the other hand shows the body mass of the penguins. After we have defined our aesthetics arguments, we can then simply tell ggplot to plot a boxplot by specifying geom_boxplot(). Easy, right?!\n\n\npenguins %>%                            # data\n  ggplot(aes(x = island,                # x value\n             y = body_mass_g)) +        # y value\n  geom_boxplot()                        # apply the BOXPLOT geom\n\n\n\n\nExercise 2.2\nAlright, so we have now plotted a boxplot. This is great, but boxplots are not necessarily always the best way to visualize data, because the distribution of the groups are not shown. A boxplot only displays the median, and the data’s quartiles. This isn’t always helpful, so we often want to somehow show the distribution of our data. We can very easily do this in ggplot by simply adding the individual data points.\nTo display the individual data points, we can add the geom geom_jitter (which is similar to geom_point(), the only difference being the dots are spread out a little more). Add geom_jitter() to the ggplot code from exercise 2.1.\n\nClick for Answer\nSOLUTION\nThe great thing about ggplot is that we can stack geoms on top of each other, adding layers to our plot. This makes it very simple to create informative plots.\nTo add the individual data points, we can simply add the geom_point() function to the plot we have already created.\n\n\npenguins %>%                               # data\n  ggplot(aes(x = island,                   # set x value\n             y = body_mass_g)) +           # set y value\n  geom_boxplot() +                         # apply BOXPLOT geom\n  geom_jitter()                            # apply JITTER geom (scattered data points)\n\n\n\n\nExercise 2.3\nNow, let’s say that we would like to color code the islands, so that each island on the boxplot has a different color. How could we do this?\nHINT Remember, if we want to specify the ASTHETICS (such as color), we need the aes() function, and in this case we would like to FILL the boxplots with color.\n\nClick for Answer\nSOLUTION\nSince we want to define some type of aesthetic, we need the aes() function. We can EITHER define this in the aes() function in the ggplot() function, or in the geom_boxplot() function (doesn’t make any difference either way). Since we want to fill the boxplots according to the island, we have to specify the fill argument in the aes() function, as seen below.\n\n\npenguins %>%                              # data\n  ggplot(aes(x = island,                  # set x value\n             y = body_mass_g)) +          # set y value\n  geom_boxplot(aes(fill = island)) +      # apply BOXPLOT geom; sep. colors for ISLAND\n  geom_jitter()                           # apply JITTER geom (scattered data points)\n\n\n\n\nExercise 2.4\nUsing the ggsave() function, save this plot as “boxplotPenguine” using a RELATIVE PATH to the folder Figures.\nHINT REMEMBER, we have to save our final plot as an object before saving it! To specify the relative path, you will need the file = argument. Don’t forget the NAME the plot in the file argument!\n\nClick for Answer\nSOLUTION\nTo save a plot, we first need to save this as an object, which the directions specified as “boxplotPenguine”. So, we first save the plot using the = operator.\n\n\nboxplotPenguine =                           # define object\n  penguins %>%                              # data\n  ggplot(aes(x = island,                    # set x value\n             y = body_mass_g)) +            # set y value\n  geom_boxplot(aes(fill = island)) +        # apply BOXPLOT geom; sep. colors for ISLAND\n  geom_jitter()                             # apply JITTER geom (scattered data points)\n\n# save boxplotPenguine object in FIGURES folder and named boxplotPenguine.pdf\nggsave(boxplotPenguine, file = \"./Figures/boxplotPenguine.pdf\")\n\n\n\nExercise 3\nEspecially when we are first having a look at our data, and when we then want to somehow plot our descriptive statistics (e.g. gender, age etc.), many are tempted to use barplots. Barplots, however, are relatively uninformative, and can oftentimes be misleading. In the words of McElreath (2015: 203)\n\nBarplots suck. […] The only problem with barplots is that they have bars. The bars carry only a little information—which way to zero, usually—but greatly clutter the presentation and generate optical illusions.\n\nIt’s therefore better to use other visualization methods such as dotplots, density plots, violin plots, eye or half-eye plots. These types of plots are extremely easy to make in R (even easier than barplots).\nExercise 3.1\nLet’s take our Vampires data frame. We would like to visualize the data distribution of age (variable: ageOfVampire) in our group using a density plot (geom_density()). When plotting a density plot, the aes() function only takes an x = argument.\n\nClick for Answer\nSOLUTION\nWhen visualizing a density plot, we as always need to define which data frame our variable(s) are saved in. In this case, this is the Vampires data frame. We then use the pipe and begin with the ggplot() function. We then need to define our x = argument in the aes() function. After, we simply apply the geom_density() function.\n\n\nVampires %>%                            # data\n  ggplot(aes(x = ageOfVampire)) +       # set x value\n  geom_density()                        # apply DENSITY geom\n\n\n\n\nExample 3.2\nAlright, now let’s say we would like to display the age distribution according to the gender of the vampires. To do this, we can apply the fill argument to the aes() function, and instructing ggplot to plot the ageOfVampire variable, filling the density plots by gender.\nApply the variable gender to the fill argument in the aes() function.\n\nClick for Answer\nSOLUTION\nNow, to plot the density plots according to gender, all we need to do is apply the fill argument to the aes() function.\n\n\nVampires %>%                              # data\n  ggplot(aes(x = ageOfVampire,            # set x value                 \n             fill = gender)) +            # fill density with colors by GENDER\n  geom_density()                          # apply DENSITY geom\n\n\n\n\nExercise 3.3\nBut WAIT! The plots overlap and we can’t see them well. We have several options here—probably the easiest is that we can make the density plots ‘lighter’, so that we can see both plots and their distributions. We do this by applying the alpha argument to the respective geom.\nApply the alpha = .4 argument to the geom_density() function. After, play with changing the .4 to higher / lower (between 0 and 1) to see what this function does.\n\nClick for Answer\nSOLUTION\nTo make the density plots more transparent, we can apply the alpha argument and adjust the degree of transparency.\n\n\nVampires %>%                           # data\n  ggplot(aes(x = ageOfVampire,         # set x value\n             fill = gender)) +         # fill density with colors by GENDER\n  geom_density(alpha = .4)             # apply DENSITY geom; transparency 40%\n\n\n\n\nExercise 4: The Ugly Plot\nHere a list of common geom_ functions: Use this list to test out different geoms on the Vampires, Iris or Penguine data frames.\nWHO CAN MAKE THE UGLIEST PLOT?!\nTake 15-20 minutes and (either alone or in groups) attempt to make the absolut worst, ugliest, horribly looking and utterly vomit-worthy plot you can manage by stacking geoms on top of each other.\nAnd don’t forget to test out different ggplot2 THEMES!!\nSave this plot, USING A RELATIVE PATH, in the Figures folder as a .png file under the name uglyPlot_your initials.png\nSend this to me via E-Mail (mason.wirtz@stud.sbg.ac.at) once you are finished.\nAdvanced: Visualizing GAMs using ggplot2\nWhen working with any type of data, visual analysis should always be your first step. Before deciding on the distribution of a model, it is worth considering whether the nonlinearity of a predictor-outcome relationship is pronounced enough to justify using methods other than linear methods.\nIf you’re ever interested in using generalized additive models (GAMs), it is also entirely possible to visually diagnose whether the data you are dealing with are nonlinear enough to advocate/justify using GAMs.\nLet’s say we are interested in visualizing the nonlinear effects of age of the vampires on the number of people a vampire has changed into vampires, with seperate smooths fitted to gender. We can diagnose whether a GAM is perhaps justified by plotting this using the geom_smooth function, specifying the method as “gam” and the formula as y as a function of the smooth term x. This shows us a relatively linear model, so we might think twice before using a complexer model such as a GAM or GAMM.\n\n\nVampires %>%                               # data\n  ggplot(aes(x = numberChangedToVamp,      # set x value\n             y = ageOfVampire)) +          # set y value\n  geom_point() +                           # apply POINT geom (data points)\n  geom_smooth(aes(color = gender,          # apply SMOOTH geom; sep. color for GENDER\n                  fill = gender),          # fill color by GENDER\n              method = \"gam\",              # smoothing method GAM \n              formula = y ~ s(x)) +        # formula for smoothing function; nonlinear x\n  scale_color_viridis_d(\"gender\") +        # define color scheme\n  scale_fill_viridis_d(\"gender\")           # define color scheme\n\n\n\n\nLet’s take a look at what would justify using a GAM:\n\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\npacman::p_load(\n  mgcv,                               # GAMs\n  gratia                              # plot GAM\n)\n\nset.seed(4444)                        # set seed for reproducability  \ndat = gamSim(4, n = 400)              # generate nonlinear data with factors\n\n\nFactor `by' variable example\n\ndat %>%                               # data\n  ggplot(aes(x = x2,                  # set x value\n             y = y)) +                # set y value\n  geom_point() +                      # apply POINT geom (data points)\n  geom_smooth(aes(color = fac,        # apply SMOOTH geom; color by FAC\n                  fill = fac),        # fill by FAC\n              method = \"gam\",         # smoothing method GAM \n              formula = y ~ s(x)) +   # formula for smoothing function; nonlinear x\n  scale_color_viridis_d(\"fac\") +      # define color scheme\n  scale_fill_viridis_d(\"fac\")         # define color scheme\n\n\n\n\nWe see very clear nonlinear trends. Let’s compare this to output after we have decided to run a GAM.\n\n\nmodel =                       # define object\n  bam(y ~ s(x2, by = fac),    # y as a nonlinear function of x2; sep. smooths for FAC\n  data = dat                  # data argument\n)\n\ndraw(model) &                 # plot effects, quick and dirty\n  theme_bw()                  # change scheme\n\n\n\n\nGiven there are no extra random effects/factor smooths to be taken into account, this should provide us with the same smooths as shown above.\n\n\n\n",
      "last_modified": "2022-03-04T20:42:30+01:00"
    },
    {
      "path": "ExercisesUnit8.html",
      "title": "8. Reporting and reproducibility",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nThis Study\nResearch Questions\nParticipants\nTasks and Instruments\nStatistical analysis (group work advised)\n\nResults\nRQ1: How can the (socio-)demographics of this vampire sample be characterized?\nRQ2: What background variable(s) predict the amount of humans a vampire changes into a vampire?\n\n\nWhen we conduct a study, we want to report it, right? Of course, our first step might be to publish the study, but what about all that extra, supplementary material? Or what if you would just like to document your work and analysis process in one big document? R Markdown is the way to go!\nIn this report, we are going to report on the Vampires data frame. We are going to outline our results and document our work process as we go.\nOn an important note, the directions in this exercise are very vague—there is a reason for that. While there are, of course, guidelines for reporting, how we choose to report results is often an individual process/decision (i.e. what do we plot? What do we show in the form of a table? Which variables do we plot/describe first?) This exercise is set up in a manner similar to the methods and results section of a paper. I will give you broad guidelines, but now it is your turn to develop an individual process of how you would like to report using R Markdown.\nTake this exercise as a free-for-all. Plot excessively, practice manipulating data and most importantly: ASK QUESTIONS! There are binary factors, categorical factors and numeric factors, so there are a lot of plotting and reporting possibilities. Use this exercise to take what we have learned and apply it to a reporting situation.\nWhile you can work alone for this exercise, I suggest group work to bounce ideas off of one another. It is also a great space to get to know other reporting styles.\nLet’s get started!\nThis Study\nGiven the dearth of empirical research on the background lives of vampires and what influences certain domains of their decision making process (particularly, turning another person into a vampire), a questionnaire study was conducted. The present contribution in particular aims to ascertain the respective influence and predictive power of exploratory background variables on the number of humans vampires have turned into vampires. These results should thus give rise to new research initiatives delving into e.g. socio-affective, psycho-cognitive and background predictor variables of vampires’ decision making processes.\nResearch Questions\nGiven the small number of vampires in comparison to humans, the primary goal of this study was to determine what animates a vampire to change a human into a vampire. The following exploratory research questions will be addressed:\nRQ1: How can the (socio-)demographics of this vampire sample be characterized?\nRQ2: What background variable(s) predict the amount of humans a vampire changes into a vampire?\nThe first research question takes a descriptive approach, mapping out (a) how many cities the average vampire has visited; (b) the number of children the average vampire has and (c) how many people the average vampire has changed into a vampire. These results should shed light on the lives vampires have led hitherto. Several background variables were also collected, i.e. gender (binary; male vs. female, no vampires identified as diverse in this sample), age (numerical), state of living (binary; dead vs. alive—interestingly, the response quote by the dead vampires was unexpectedly high), whether the respective vampire identifies as having fangs (binary; yes vs. no) and where the respective vampires was born (categorical; continent).\nThe second question aims to ascertain how select background variables are statistically related to the number of humans a vampire changes into a vampire.\nParticipants\nTASK: Using descriptive statistics (mean, standard deviation, max., min., etc.), outline the participant group in question. Which variables are important to outline here? Should these be reported using tables? Is there a reason to plot any of the variables? How could we plot some of these variables? Remember, it’s important to visually display your data (even if you don’t publish the plots) so as to get to know your data better!!\nTasks and Instruments\nA questionnaire was used to collect data on the variables in question. Via personal networks and social media, participants were recruited. The questionnaire was administered in a quiet, distraction-free room. In future studies, it would be advisable to conduct such studies via online questionnaire tools such as LimeSurvey, as multiple student assistants suddenly disappeared during the face-to-face data collection process (reason unknown).\nStatistical analysis (group work advised)\nTASK: The inferential goal of this study is to ascertain the respective influence of (several) predictor variable(s) on the amount of humans a vampire has changed into a vampire. What inferential methods could we use to do this? Discuss with a partner!\nDon’t forget to think about variable transformations! E.g. centering variables, standardizing variables etc.\nAfter you have decided on which statistical analysis methods you might want to use, look up packages/functions with which these can be done. Do you need any extra packages? Are there methods included in base R?\nIf you are a novice, there are two simple methods you can use: linear regression or correlation analyses.\nCorrelation analysis: A correlation anaysis does not assess the effect of a predictor variable on a response variable, but rater judges the strength of a relationship between two variables (r value between -1 (perfect NEGATIVE relationship) and 1 (perfect POSITIVE relationship)). For those not yet fit in statistical analysis, this would be a good method to start with. In base R, we can use the cor.test() function.\nLinear regression: This assesses the respective effect of the predictor variable x (or predictor variableS x + x + x…) on the response variable y (numberChangedToVampire). For simple linear regression, we can use the base R function lm()\nResults\nRQ1: How can the (socio-)demographics of this vampire sample be characterized?\nTASK: Using tables, plots and however you feel you can best answer this research questions, report the results that answer this research question. You should present descriptive statistics and/or visual displays of the variables contained in the data set (with the exception of the id variable, of course). Don’t forget to provide short descriptions of your work process, and make sure to comment your code in the respective code chunks!\nRQ2: What background variable(s) predict the amount of humans a vampire changes into a vampire?\nTASK: Using what you discussed in the statistical analyses, do your best to use these methods to assess the respective relationship between predictor variables (your choice which variables you choose) and the amount of humans a vampire changes into a vampire.\n\n\n\n",
      "last_modified": "2022-03-04T20:42:30+01:00"
    },
    {
      "path": "ExercisesUnit9.html",
      "title": "9. You don’t just knit with needles: Knitting in R Markdown",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nExercise 1\nExercise 1.1\nExercise 1.2\n\nExercise 2\nExercise 2.1\nExercise 2.2\n\n\nExercise 1\nUsing the Knit tab, knit your R Markdown document into a HTML file.\nExercise 1.1\nThe default settings for the HTML output are rather dull…that’s why we sometimes change one thing or another to make the document more readable or other suitable for our needs. Using the number_sections argument, reformat the output code of your report document from exercise 8 to number the sections in the document.\n\nClick for Answer\nSOLUTION\nTo do this, we would need to make sure we have defined the output style: html_document: and then tabbed in, number_sections: true\nExercise 1.2\nUsing the toc argument, reformat the output to include a table of contents.\n\nClick for Answer\nSOLUTION\nTo do this, we would need to make sure we have defined the output style: html_document: and then tabbed in, toc: yes\nExercise 2\nExercise 2.1\nTake at look at the two documents below and have a look at the following output arguments (these are included in the output formats in the first few lines of each document).\nDocuments (raw analysis scripts):\nDocument 1\nDocument 2\nWhat do you think the following output arguments do? How do they change the HTML output of the respective document?\nOutput arguments:\ntoc_float\ncode_folding\nfig_height\ntheme\nhighlight\nExercise 2.2\nThe next several links lead to the HTML outputs (you will have to click on the blue download button in the upper right corner to view the HTML documents).\nDocuments (HTML outputs):\nDocument 1\nDocument 2\nCompare your assumptions about what the respective HTML outputs do with what you see in the documents. How do these documents differ to those you knitted in the previous exercises?\n\n\n\n",
      "last_modified": "2022-03-04T20:42:31+01:00"
    },
    {
      "path": "ggplotScript.html",
      "title": "ggplot2 Script",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\n\n################################## #\n# ggplot2 script                   #\n################################## #\n\n# PRELIMINARIES ----\n# clear work space\nrm(list = ls())\n\n# libraries\nlibrary(tidyverse)           # load in tidyverse\n\n# set ggplot2 theme\ntheme_set(theme_linedraw(12))\n\n# data\ndiamonds = diamonds          # diamonds data frame\npenguins = penguins\n\n# PLOTS FOR POWERPOINT ----\n# no geoms ----\ndiamonds %>%\n  ggplot(aes(x = price))\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/aesthetics.png\")\n\n# geom_histogram ----\ndiamonds %>%\n  ggplot(aes(x = price)) +\n  geom_histogram()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_histogram.png\")\n\n# geom_density ----\ndiamonds %>%\n  ggplot(aes(x = price)) +\n  geom_density()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_density.png\")\n\n# geom_freqpoly ----\ndiamonds %>%\n  ggplot(aes(x = x)) +\n  geom_freqpoly()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_freqpoly.png\")\n\n# geom_bar ----\ndiamonds %>%\n  ggplot(aes(x = color)) +\n  geom_bar()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_bar.png\")\n\n# geom_point ----\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm)) +\n  geom_point()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point.png\")\n\n# geom_jitter ----\ndiamonds %>%\n  ggplot(aes(x = price,\n             y = carat)) +\n  geom_jitter()\n\n\n\n# geom_smooth ----\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm)) +\n  geom_smooth()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_smooth_gam.png\")\n\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm)) +\n  geom_smooth(method = \"lm\")\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_smooth_lm.png\")\n\n# geom_boxplot ----\ndiamonds %>%\n  ggplot(aes(x = cut,\n             y = carat)) +\n  geom_boxplot()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_boxplot.png\")\n\n# geom_barplot_identity ----\ndiamonds %>%\n  ggplot(aes(x = cut,\n             y = carat)) +\n  geom_bar(stat = \"identity\")\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_barplot_identity.png\")\n\n# geom_violiny ----\ndiamonds %>%\n  ggplot(aes(x = cut,\n             y = carat)) +\n  geom_violin()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_violin.png\")\n\n# geom_point_aesthetics\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm,\n             color = species)) +\n  geom_point()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point_aesthetics1.png\")\n\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm,\n             color = species,\n             shape = species)) +\n  geom_point()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point_aesthetics2.png\")\n\n# geom_point + geom_smooth\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm,\n             color = species)) +\n  geom_point() +\n  geom_smooth()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point_geom_smooth.png\")\n\n# geom_point + geom_smooth + geom_smooth_linear\npenguins %>%\n  ggplot(aes(x = bill_length_mm,\n             y = bill_depth_mm,\n             color = species)) +\n  geom_point() +\n  geom_smooth() +\n  geom_smooth(method = \"lm\",\n              color = \"black\")\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/geom_point_geom_smooth_geom_smooth_linear.png\")\n\n# geom_jitter + geom_smooth + color_species\npenguins %>%\n  ggplot(aes(x = species,\n             y = bill_depth_mm,\n             color = species)) +\n  geom_boxplot() +\n  geom_jitter()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/boxplot_jitter_color.png\")\n\n# geom_jitter + geom_smooth + fill_species\npenguins %>%\n  ggplot(aes(x = species,\n             y = bill_depth_mm)) +\n  geom_boxplot(aes(fill = species)) +\n  geom_jitter()\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/boxplot_jitter_fill.png\")\n\n# geom_jitter + geom_smooth + fill_species + labs\npenguins %>%\n  ggplot(aes(x = species,\n             y = bill_depth_mm)) +\n  geom_boxplot(aes(fill = species)) +\n  geom_jitter() +\n  labs(x = \"Species\",\n       y = \"Bill Depth (in mm)\",\n       title = \"Bill Depth by Species\",\n       subtitle = \"A cool plot\")\n\n\n\nggsave(plot = last_plot(),\n       filename = \"./Figures/boxplot_jitter_labs.png\")\n\n\n\n\n\n\n",
      "last_modified": "2022-03-04T20:42:46+01:00"
    },
    {
      "path": "index.html",
      "title": "IntRo to RStudio and R Markdown",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\nLet’s get started!\nPrerequisites\nThe first step is to download RStudio. If you have not done so already, you can find the links and the directions on how to do this here.\nUsing this website\nThis website accompanies the workshop. All slides are available on this page, as well as on this workshop’s OSF page. You are also free to check out this website’s repository, which shows the source codes, in case anyone is interested.\nThe hands-on exercises are all available as R scripts under Exercise scripts—the exact same exercises AND THEIR SOLUTIONS (hidden, unless you click the Click for answer button under each exercise) are available under Exercises. All solutions have thorough explanations so you can reference them again and again in the future if need be.\nCheck list\nHere is a summary of all the prepping steps.\n\nDownload RStudio (essential)\n\nCreate an OSF account here (optional)\n\nBrowse the Getting started pages\n\n\n\n",
      "last_modified": "2022-03-04T20:42:47+01:00"
    },
    {
      "path": "Schedule.html",
      "title": "Schedule",
      "author": [
        {
          "name": "Mason A. Wirtz",
          "url": "https://masonwirtz.github.io"
        }
      ],
      "contents": "\n\nContents\nSchedule\nDay 1. Getting wet in the coding waters: Basics of RStudio\n0. Introductions\n1. Introduction to RStudio\n2. Baby steps: Basics of coding in RStudio, part 1\n3. Baby steps: Basics of coding in RStudio, part 2\n4. The tidier the better: Basics of coding with the Tidyverse\n\nDay 2. Give me an R for reproducibility: Basics of R Markdown\n5. Setting up a project\n6. Code chunks in R Markdown\n7. Let’s get plotting\n8. Reporting and reproducibility\n9. You don’t just knit with needles: Knitting in R Markdown\n10. Fun with coding\n\n\n\nSchedule\nDay 1. Getting wet in the coding waters: Basics of RStudio\n0. Introductions\n(13:00—13:45)\nHellos, introductions\nWhat kind of data are we working with?\nGetting to know the website\n1. Introduction to RStudio\n(13:45—14:15)\nWhich panes exist?\nHow can I read in data?\n2. Baby steps: Basics of coding in RStudio, part 1\n(14:15—15:00)\nVectors\nFactors\nData frames\n3. Baby steps: Basics of coding in RStudio, part 2\n(15:00—16:00)\nObjects\nFunctions\nPackages\n4. The tidier the better: Basics of coding with the Tidyverse\n(16:00—17:00)\nTibbles\nData wrangling with dplyr\nPiping with magritter\nDay 2. Give me an R for reproducibility: Basics of R Markdown\n5. Setting up a project\n(09:00—10:00)\nHow do I create an .Rproj file?\nHow can/should I structure my folders/files?\nRelative/absolute file paths\n6. Code chunks in R Markdown\n(10:00—11:30)\nWhat is a code chunk in R Markdown?\nStructuring code chunks\nLUNCH\n7. Let’s get plotting\n(12:30—14:30)\nPlotting with ggplot2\nSaving ggplots\n8. Reporting and reproducibility\n(14:30—15:30)\nR Markdown syntax\nInline formatting\nBlock-level elements\n9. You don’t just knit with needles: Knitting in R Markdown\n(15:30—16:00)\nKnitting an HTML document\nKnitting a Word document\nUploading/downloading from OSF\n10. Fun with coding\n(16:00—17:00)\nWorking with your own data\nQuestions, individual work\nNote: If you don’t have your own data, send me a short description of your project and I will simulate data similar to the data you will be working with so that you have something to practice!\n\n\n\n",
      "last_modified": "2022-03-04T20:42:47+01:00"
    }
  ],
  "collections": []
}
